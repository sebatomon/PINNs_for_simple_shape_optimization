{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple PINN for an elastic plate with an elliptical hole "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometry\n",
    "\n",
    "We want to model a quarter of a plate with an elliptical hole. The domain itself is represented by collocation points, the boundaries are represented by uniformly sampled points along the perimeter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#C9C5BC"
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          0.13998097901958667,
          0.3104700644706484,
          0.2568291596027048,
          0.0724940898079326,
          0.4632471385995713,
          0.4784436073700046,
          0.057776802175536685,
          0.13505759213796503,
          0.11818959140345406,
          0.06443621036730002,
          0.20071429465678847,
          0.14672417121954817,
          0.5182815377040905,
          0.15833526982667537,
          0.03160193791287499,
          0.12853280502757566,
          0.9179029957243414,
          0.1694199729036262,
          0.013352384737322939,
          0.03427809349018135,
          0.19187172294376728,
          0.27024710695409865,
          0.08247729013906692,
          0.37245729906578073,
          0.3096670124355303,
          0.5811087894773069,
          0.40526490163641476,
          0.2121730413481266,
          0.8152335633586256,
          0.5586355819838894,
          0.03562963662430162,
          0.4125910162520552,
          0.6983116084685629,
          0.18673006585561655,
          0.21084953346599158,
          0.10465493704532124,
          0.6415550127477918,
          0.9015559742402045,
          0.18941308537821416,
          0.836993638440089,
          0.10402537205653657,
          0.06958304631768761,
          0.16202667141910287,
          0.0685366001082347,
          0.9111424693537014,
          0.1838155470782783,
          0.4421704471807454,
          0.31985943043158394,
          0.9172566821709343,
          0.4220679316396531,
          0.16667531567156135,
          0.6287369313760586,
          0.17444191583829208,
          0.7644102046369069,
          0.24831359152582227,
          0.36506073363532116,
          0.07931278749122116,
          0.05497730424269699,
          0.17384886540889405,
          0.762390755233338,
          0.5433039743788585,
          0.14541366501970276,
          0.027353614397567092,
          0.12139371635731383,
          0.7378227572369946,
          0.05089369919054309,
          0.9519124240734561,
          0.41186642396918516,
          0.2800218382749302,
          0.32853410638134567,
          0.20789031084173787,
          0.11190874492058454,
          0.6684881167835057,
          0.9706034384146123,
          0.21298329899160498,
          0.14381961397246712,
          0.13298835922520796,
          0.08612867405109312,
          0.3950339560028949,
          0.41890217150705533,
          0.9391242876677429,
          0.199159240663509,
          0.2112615074957568,
          0.1157679978542316,
          0.4791066082064167,
          0.19332044486450978,
          0.19794142004702955,
          0.4189365584650041,
          0.4734021145020926,
          0.7909871630697373,
          0.20021547658136107,
          0.10161636560769831,
          0.4271387764278164,
          0.07512128153213492,
          0.573691468743005,
          0.3480485820964419,
          0.2757822202886023,
          0.17176430427717362,
          0.07451692779839487,
          0.5093506198406349,
          0.4154598451583584,
          0.12246373998075644,
          0.10601527583973883,
          0.20710342992036399,
          0.16238436028180933,
          0.4156490816713439,
          0.4004520854081841,
          0.03828477591098131,
          0.13675043262665051,
          0.16576830058963074,
          0.8974059722849901,
          0.09266723395880644,
          0.4322854275401076,
          0.19320537677179764,
          0.6127325637204329,
          0.3942272685287541,
          0.09904498343713015,
          0.5510970915215306,
          0.9429658942563345,
          0.14634756818218522,
          0.5490805481616559,
          0.9324534682295504,
          0.06481684464212908,
          0.03589667946516135,
          0.6199271639727157,
          0.05389177741088704,
          0.10325708217277034,
          0.41515038668691373,
          0.9204607955014412,
          0.2296978850356416,
          0.32089224177703335,
          0.7162190091191464,
          0.002702300483549811,
          0.28723151410175857,
          0.8390889440391173,
          0.38978529352206515,
          0.1884725989722112,
          0.05671061192030771,
          0.9210827102870379,
          0.06916341359553492,
          0.38306042851613137,
          0.16704464158602986,
          0.058742435703149805,
          0.05735010855927038,
          0.006414548631064647,
          0.33995742163756226,
          0.5877618418682382,
          0.43838158402146327,
          0.42144070662963007,
          0.3609693979606215,
          0.9955275325896952,
          0.1747420289657957,
          0.4456859981979892,
          0.3489189073239109,
          0.2535977940448648,
          0.20779194936058867,
          0.23428426583666148,
          0.04854041401637747,
          0.7279689167623462,
          0.6365700373230007,
          0.8043908313367677,
          0.29432337806497566,
          0.25551643012919384,
          0.3362291247991566,
          0.017921350334283576,
          0.20256486393441614,
          0.0159256022839582,
          0.04324057555416938,
          0.2849665384499638,
          0.5218281536038274,
          0.2022147369525323,
          0.32862545983342156,
          0.41640080774029287,
          0.015089140179336755,
          0.2385164900097096,
          0.14370724859661016,
          0.6705651298624472,
          0.23479366023044168,
          0.7608699663444106,
          0.8424624270977457,
          0.11685286013299152,
          0.0393437927764171,
          0.09981220790368805,
          0.04135761573578333,
          0.7257933539935203,
          0.32677566977163125,
          0.42306527654603904,
          0.18861911435829976,
          0.05998100286304182,
          0.17635213127788243,
          0.2596635180043695,
          0.13746447117487498,
          0.06090154492792634,
          0.14439527396173268,
          0.3129739452389804,
          0.14525979021059343,
          0.932384668891861,
          0.012440156624255417,
          0.7748660553762076,
          0.7478202066867584,
          0.44819853727899717,
          0.5685178064109605,
          0.033588500466019786,
          0.5817803058760811,
          0.20077215074144036,
          0.004393986371817324,
          0.5120873221624639,
          0.13626233342473948,
          0.750455786058616,
          0.5809982594961646,
          0.9304369503886107,
          0.6718610440403099,
          0.7086626018924097,
          0.33701499170709404,
          0.5264354545663281,
          0.7728726826374664,
          0.19065182763738822,
          0.40934357650625464,
          0.24205251573531922,
          0.02663662122163457,
          0.0044687556042543,
          0.722651111708245,
          0.05312774531613623,
          0.04032895065683997,
          0.44335535154418365,
          0.16409390940880797,
          0.11642211147381255,
          0.11969869969673277,
          0.555407969992233,
          0.08650068300203324,
          0.7550835140095933,
          0.13197127644370685,
          0.1953611855241695,
          0.8024656679599509,
          0.12821054517687414,
          0.8915181789170332,
          0.20067119287581972,
          0.05434962237387627,
          0.19739556418273557,
          0.19856212185362312,
          0.4431757348862376,
          0.2804709197251721,
          0.09722127742683023,
          0.2175069497745947,
          0.09989452236805801,
          0.388262597967353,
          0.08049699549421037,
          0.32279181556945363,
          0.28269767726001305,
          0.1403337679187389,
          0.3061929993907399,
          0.64059395574384,
          0.6665500245798882,
          0.11668496059133918,
          0.054742703348228505,
          0.36909810410791216,
          0.1519767019963862,
          0.403455942667364,
          0.2183122951295913,
          0.18068841734533383,
          0.002847803965881104,
          0.5748764644979764,
          0.6097530004477573,
          0.014229746343292127,
          0.14704327703123424,
          0.10910986768578566,
          0.24124610022619833,
          0.18002428837082463,
          0.07015101624358738,
          0.20970299094078573,
          0.15069188096361708,
          0.28573294293653273,
          0.6292717885202804,
          0.011464033884099839,
          0.11737403609010216,
          0.02190941272086103,
          0.22890794598450617,
          0.183260137355431,
          0.09635338725363983,
          0.7181096883108046,
          0.11229882654033196,
          0.3903300849752161,
          0.5061665643310568,
          0.20755805897275284,
          0.5540296313253867,
          0.7399958691374395,
          0.1547143913840721,
          0.016145031827961138,
          0.4228366373691701,
          0.23914496677674152,
          0.00198821282131562,
          0.23774772117149953,
          0.1326357681217118,
          0.005677910506564466,
          0.6319481828103054,
          0.09289764556023658,
          0.7433353657350875,
          0.007050482301623369,
          0.23472905738922858,
          0.21075198814201082,
          0.6768453305423021,
          0.453810235820542,
          0.0984639531285742,
          0.30476066284227366,
          0.26798700651843976,
          0.15898407413193943,
          0.1478490761162394,
          0.4469708898826084,
          0.9550904175833463,
          0.3143753052729789,
          0.14807714547644055,
          0.5449511873703825,
          0.03300089614631037,
          0.2453727392880463,
          0.10419046005787284,
          0.10382728519896435,
          0.12793783605718723,
          0.44106043951380663,
          0.44561881010179505,
          0.3138860810928632,
          0.3257242016658003,
          0.34095588605500043,
          0.08280107674348297,
          0.2626092326997464,
          0.47638833728532326,
          0.32479359927741575,
          0.05796425933975823,
          0.11146599452049723,
          0.25513475550023973,
          0.47993331185215576,
          0.08408008887057802,
          0.3618234232729127,
          0.38629490769690195,
          0.12441622210692774,
          0.3626330009821139,
          0.12820477136637903,
          0.18748337329957565,
          0.15397982121912004,
          0.21928483929118833,
          0.19582801377033174,
          0.06771351737325891,
          0.23402412952750057,
          0.15616627060325633,
          0.5045806850411337,
          0.07656201333081343,
          0.7470145907301715,
          0.00902244839404112,
          0.9383458944812416,
          0.5120998438032226,
          0.06262064303754575,
          0.9425111813273384,
          0.05668107528181579,
          0.7541291659446367,
          0.24095014434787573,
          0.7577108512557035,
          0.057577294114967155,
          0.598085652297006,
          0.21854715822776394,
          0.4945014998659954,
          0.2542656771491798,
          0.06609154329082077,
          0.8036948890298053,
          0.6725988445674732,
          0.2178722286430017,
          0.982634977690927,
          0.6055956478499588,
          0.7994044227726217,
          0.16293803995943495,
          0.15791191482006542,
          0.18939767246651404,
          0.4403840196751293,
          0.22741501895242933,
          0.5305573722501569,
          0.8921565251443367,
          0.005647024569185793,
          0.26436260430434805,
          0.7807203334577968,
          0.18739870598121233,
          0.12688092900955014,
          0.014139269692294105,
          0.7187359069666687,
          0.10524719969007511,
          0.5195901506338525,
          0.10517490036412194,
          0.1640394254839656,
          0.09432298004166344,
          0.5158655243388143,
          0.17026607835116286,
          0.017848439389252308,
          0.9791126385571439,
          0.34291835437456647,
          0.03678731318086293,
          0.20601086014408299,
          0.9807126056080508,
          0.18817399920141778,
          0.04340653638074833,
          0.3811575776736977,
          0.325508046954393,
          0.16712816017989188,
          0.08528693624913573,
          0.6551815837652083,
          0.7079111744250611,
          0.14150966239990687,
          0.022890447041696602,
          0.8328442071036138,
          0.3040430430794442,
          0.28661830238597424,
          0.465343761157608,
          0.11405735884963504,
          0.27714388017874064,
          0.2690833890990367,
          0.04186098049303107,
          0.9446778236860194,
          0.391664788551954,
          0.6281500614246321,
          0.687499971894116,
          0.5755649374701463,
          0.4596515193104637,
          0.6355677772901263,
          0.16288748322242091,
          0.6732527306684608,
          0.20053543175406263,
          0.12025835873512367,
          0.47124879798823577,
          0.08764795486156364,
          0.3795906056725828,
          0.016759262439611445,
          0.32650198452989665,
          0.9817964682625808,
          0.8325529992348366,
          0.1974017083164773,
          0.03851324580296724,
          0.11203957081432794,
          0.2489449804623969,
          0.403506481375459,
          0.0028789100738462717,
          0.05344346123852626,
          0.6959530481375121,
          0.1962791593489493,
          0.01472179995302461,
          0.13011288753855627,
          0.4054487607973754,
          0.30034730722696584,
          0.3721713737439163,
          0.5838040832721384,
          0.03274065885860986,
          0.8409183514784302,
          0.6711322570966715,
          0.5904843828741354,
          0.16039553545367127,
          0.21311084663797503,
          0.3402197290551733,
          0.3478674619956605,
          0.05870474016280602,
          0.4557277642852121,
          0.9227952494735866,
          0.7272992129517609,
          0.37164314079305244,
          0.4369129837637501,
          0.321449716731084,
          0.16261682360380178,
          0.13874884697320108,
          0.10703259719747596,
          0.7941397541122642,
          0.2037621091746959,
          0.16349598041077115,
          0.27859869744308463,
          0.07791299738509458,
          0.01813043738489,
          0.3638183695755274,
          0.17553136533069255,
          0.7192345126276763,
          0.1593831062026347,
          0.296186090811057,
          0.3714318083980883,
          0.11054425898758052,
          0.09516428783697203,
          0.18532703513079551,
          0.13498507310603547,
          0.5870032629818049,
          0.19798320039730585,
          0.2819546296978954,
          0.329983518115971,
          0.1736606472176887,
          0.37432929461671144,
          0.021365689487965106,
          0.26304867842049506,
          0.4483059373564355,
          0.18604437985123518,
          0.6448015823353472,
          0.7301763163428444,
          0.34083611201890546,
          0.16400480233033635,
          0.7494754277807801,
          0.04228604560494247,
          0.10303346653971021,
          0.15333896366639344,
          0.47163568683537177,
          0.5205711453118647,
          0.35111243771351475
         ],
         "y": [
          0.18625274394954333,
          0.21478034929115478,
          0.11408675737907621,
          0.23271844308643214,
          0.33449215439151353,
          0.11017073280998156,
          0.41416964874233486,
          0.0190294682358693,
          0.08009812495114822,
          0.10522238124148756,
          0.14505875063434284,
          0.059252275457107664,
          0.19510552365755593,
          0.4792744980443247,
          0.1484793602825499,
          0.29974771536571243,
          0.6082624634849566,
          0.08500734406810212,
          0.7506815230511756,
          0.6051582643291711,
          0.07697506800381626,
          0.1218288025674923,
          0.2567906301924316,
          0.16189327629128158,
          0.6143296212276625,
          0.19909970793822754,
          0.7067178955338735,
          0.29220674551228265,
          0.20788659069016513,
          0.2042652888246388,
          0.2472228929279893,
          0.1643357868359796,
          0.1146820772327241,
          0.36284746096703707,
          0.07173214309703993,
          0.4130491230795873,
          0.7645693064322087,
          0.3321911910070405,
          0.06369179500349693,
          0.06668874434461432,
          0.054327080238314875,
          0.38638836062287474,
          0.04664669364788888,
          0.07783858639804951,
          0.5499309367274994,
          0.21279385178195626,
          0.15391360712095226,
          0.03195328069419519,
          0.06948531964445233,
          0.4639568375068907,
          0.1776139109063693,
          0.18203535590159897,
          0.048460081399144775,
          0.44968749241413775,
          0.07111502027945857,
          0.2168550440398353,
          0.10789107553474979,
          0.07544416296330834,
          0.0999541411023079,
          0.11552774021980047,
          0.028232340319425904,
          0.05110618369446486,
          0.07487028057319077,
          0.2457032449040504,
          0.7272304040213554,
          0.3321751460152304,
          0.6661878916402929,
          0.09502374492867979,
          0.3048636854433988,
          0.015726508760812916,
          0.4609201144711967,
          0.11769599383602165,
          0.16473966575139293,
          0.9099934210531764,
          0.014789958368207266,
          0.013738157613693512,
          0.03738190134984246,
          0.23611817014686762,
          0.09604948314719798,
          0.8115374100864025,
          0.11420995085858075,
          0.12423167063721056,
          0.2724826871229366,
          0.11757927655173843,
          0.03835632368766599,
          0.2825777079096447,
          0.0182314502003705,
          0.39954049607730974,
          0.1266790677425477,
          0.08424128153665743,
          0.05312874561016974,
          0.17921462191729484,
          0.03610249807464882,
          0.11430494634563311,
          0.42396046055154496,
          0.15212485275474433,
          0.2132835632037296,
          0.8907496737218965,
          0.12371811450370183,
          0.33913103252060106,
          0.24629334244088502,
          0.03630815656807035,
          0.13533079426221106,
          0.10911148998249787,
          0.27305848882755857,
          0.0716338983398847,
          0.013075386119870306,
          0.2276884448702486,
          0.05045707470677636,
          0.20582851738002686,
          0.19634229108145146,
          0.09514118755348634,
          0.33631170345667805,
          0.05498715242734287,
          0.31166039282953045,
          0.018467469518139556,
          0.6203401841752727,
          0.3235285185695634,
          0.8182334163311147,
          0.006117607511542268,
          0.13626973558626057,
          0.33307369792353975,
          0.7618264242301134,
          0.11735947401533137,
          0.06986651836187088,
          0.06762773383560909,
          0.16552339484392145,
          0.04428713335797423,
          0.45309752396897546,
          0.0858149236742617,
          0.053266513371645535,
          0.6328272366956941,
          0.6884423913950819,
          0.13935501778691006,
          0.23631032097180654,
          0.11176576783933077,
          0.21683371747803645,
          0.10374702520416983,
          0.2703527891252919,
          0.09795254503672585,
          0.1660355189500011,
          0.06034429994348294,
          0.8071959341198273,
          0.0823842155609272,
          0.4344608584312727,
          0.01331618372057896,
          0.10592954394053694,
          0.4752966412742224,
          0.019740266544851157,
          0.01895101400652853,
          0.694426569651738,
          0.10009153576754692,
          0.16866871780946893,
          0.15364596369586345,
          0.10692654036662397,
          0.043235683347442704,
          0.08011178917412504,
          0.10738203149571268,
          0.24026134202336905,
          0.09925769165376361,
          0.40910243549269015,
          0.9934858213335218,
          0.008250760675849993,
          0.03097469426948621,
          0.10951953339388529,
          0.4399855790442119,
          0.5043578924619329,
          0.0731068162656258,
          0.05399141838105258,
          0.08155933214477898,
          0.25452306276824016,
          0.006302183958362321,
          0.8168640882904725,
          0.07264672339226057,
          0.114314550165878,
          0.03772825472365434,
          0.07169493089979681,
          0.2653743400592918,
          0.24904261893475102,
          0.026846806144388207,
          0.05525804361547176,
          0.19610695874400824,
          0.5991663329807299,
          0.10046394815340863,
          0.5155220265071364,
          0.12451996404911604,
          0.14054483611271507,
          0.053012188137933756,
          0.09346037796796379,
          0.04763130056288356,
          0.02570521439058963,
          0.10326881928531219,
          0.29510754835840924,
          0.08764703307720999,
          0.11808091030379622,
          0.20751087693161513,
          0.03788724773233577,
          0.16308833081436738,
          0.5060537216616671,
          0.21578056420760247,
          0.02094221253111959,
          0.0013307842724211347,
          0.36832546125157983,
          0.6944240783838763,
          0.1586155493604276,
          0.07263258451470749,
          0.3607328070514565,
          0.5066145220864079,
          0.49533178109476184,
          0.9297454103811617,
          0.017877895241826636,
          0.4185956311150417,
          0.25532898407016424,
          0.22427317508183947,
          0.02990211200842727,
          0.5844823710289051,
          0.07360695775155018,
          0.08798485214929629,
          0.2716448814211113,
          0.07710587296138505,
          0.7898745122315555,
          0.1361211313136677,
          0.19634558183267228,
          0.24962260532213693,
          0.05226916222338273,
          0.8365315990845755,
          0.159296551395316,
          0.10441587580458,
          0.8907174772315781,
          0.08175789948350815,
          0.2626161506866338,
          0.09578559861375475,
          0.017558304219790894,
          0.31911546054121126,
          0.05258571974128029,
          0.3509741666080496,
          0.04401033591986067,
          0.37124365639758233,
          0.2797179778962917,
          0.3310413087071201,
          0.28947222999478933,
          0.005009851421082807,
          0.0563204520307616,
          0.07515893476136123,
          0.27597899561642875,
          0.08944283708094228,
          0.07522468166001813,
          0.014130962135468751,
          0.042697372095515676,
          0.2114174687692327,
          0.35177828924079607,
          0.7412759432794855,
          0.45411002846240434,
          0.06437247035032408,
          0.0710078702610916,
          0.31501465265818107,
          0.33519981479855493,
          0.014264274737085834,
          0.027889578064688503,
          0.04103313617331334,
          0.07872693185477783,
          0.9983667864457255,
          0.40918224500237665,
          0.1288909497424894,
          0.02492045845040946,
          0.08956378087294653,
          0.01485198002275554,
          0.2104214030236806,
          0.3724757502956013,
          0.3211971468729564,
          0.06759524176908671,
          0.42509751153688413,
          0.9046534968682289,
          0.07871534261369066,
          0.18120210902008865,
          0.14835969088223536,
          0.04833708861255432,
          0.03519581940448653,
          0.38294927786918753,
          0.47009706088061354,
          0.27501983117245576,
          0.3132377574364466,
          0.06376627821859877,
          0.2603129481527246,
          0.1303623647199891,
          0.33505029329901087,
          0.10000835921972447,
          0.07242781693289597,
          0.3539205894532138,
          0.22828999899008726,
          0.07707526245505082,
          0.03909729307645404,
          0.028716094728961628,
          0.32473371583909594,
          0.2837077810763596,
          0.06389268171386409,
          0.5925385468014345,
          0.42767192334500964,
          0.16168137366011207,
          0.08903726173155324,
          0.2752104489622,
          0.2128315373046966,
          0.06145848875726712,
          0.06671977022045428,
          0.08680800088156536,
          0.20038387294749357,
          0.014940622610452646,
          0.05124703559799865,
          0.32917082977171036,
          0.27097565887808156,
          0.022884398972129297,
          0.4827640513317648,
          0.5188069401629113,
          0.12940027724571374,
          0.1842175244758338,
          0.10091067473508766,
          0.3110313119225904,
          0.8669805761162425,
          0.1951428755548995,
          0.016780667542074027,
          0.030595169636063166,
          0.01072647725484142,
          0.09774441249693933,
          0.005682074553382331,
          0.06451640534307158,
          0.12785416533760707,
          0.12599782999762119,
          0.06573840047424294,
          0.9933982156498254,
          0.43838679245018297,
          0.06345929206762221,
          0.6436988128824294,
          0.038476158992784795,
          0.1251179499334805,
          0.4420758285362887,
          0.12583178810904844,
          0.06250961225506428,
          0.01849227201366385,
          0.10616837336633658,
          0.5082051778492108,
          0.07589168042425154,
          0.05850343532556611,
          0.10348204831778772,
          0.6630692986012607,
          0.0759717631661489,
          0.053394485082072236,
          0.5068421956522177,
          0.6797470585956479,
          0.10493651535635652,
          0.3731180464403833,
          0.051019910891352147,
          0.07042234639007805,
          0.0638748238353795,
          0.057296032094086076,
          0.08467866992234495,
          0.43523257159609374,
          0.3544642550666101,
          0.03159549642485941,
          0.2848194114681049,
          0.360036901659764,
          0.08198829326873432,
          0.08954447481922038,
          0.3142639225501377,
          0.03253603172575367,
          0.0390477381921279,
          0.12015852299060502,
          0.48172950126148495,
          0.7176436360753586,
          0.05341846269130798,
          0.0811516614718139,
          0.17815729469572494,
          0.5153224029890626,
          0.019738058307419894,
          0.6309632221646825,
          0.1989693463671996,
          0.062166732292252315,
          0.4957468340128486,
          0.5238911211696055,
          0.06008702163124697,
          0.2631962647501681,
          0.15601767310759565,
          0.09025116499108181,
          0.4851852399324254,
          0.08641014798112004,
          0.1082475400631735,
          0.5190127963161107,
          0.41396666349148636,
          0.03619546178821608,
          0.09215078854614876,
          0.4353478447659968,
          0.14098461251665356,
          0.07408084741060084,
          0.17604850830156396,
          0.5489235165483591,
          0.06493360402413853,
          0.37095493013630143,
          0.4225921596620109,
          0.015994476314938846,
          0.1013662878343134,
          0.09295181089513165,
          0.71240606546853,
          0.07044174937266244,
          0.015019278877847524,
          0.08914666157535132,
          0.24424995253954881,
          0.11548011461906546,
          0.002191964159331055,
          0.13130300409976475,
          0.0734372030688745,
          0.01672935899919674,
          0.046345661499523676,
          0.07405280519322142,
          0.5501720320317354,
          0.03866139866570098,
          0.2819985806325374,
          0.1694705374651024,
          0.06890352987289568,
          0.005017539262268649,
          0.24196834691785996,
          0.26172593458959764,
          0.447281220314309,
          0.03945585348826721,
          0.04899699698689369,
          0.26970586175047667,
          0.08099658179817064,
          0.023352611712698413,
          0.11532713795095464,
          0.12552533268207033,
          0.07868900707912946,
          0.9356467705732779,
          0.03238393209060431,
          0.16446251028007436,
          0.052238491425890966,
          0.16864162722858891,
          0.24151544649638357,
          0.1376207913529485,
          0.2839720788000824,
          0.12773511736966944,
          0.04058378660029591,
          0.3629048375949556,
          0.23307023316083691,
          0.5814509910749344,
          0.0046593317607360055,
          0.07202589401304858,
          0.13738909410688646,
          0.08869653772607568,
          0.11781300964193989,
          0.15616227215823814,
          0.1794973320716263,
          0.03633710190247243,
          0.06667073285573782,
          0.29424414940165505,
          0.05892116858589052,
          0.07862251359628675,
          0.10255495376597007,
          0.3688263098767374,
          0.32384856271546664,
          0.1919298925924992,
          0.565029577138519,
          0.20889399095175024,
          0.05457900446388289,
          0.10169625656825093,
          0.050458473753706726,
          0.09643739629348025,
          0.17037108936545245,
          0.0066653339833260385,
          0.03871160260571908,
          0.22914002437197303,
          0.2102525391607012,
          0.058685059114763974,
          0.7389174728196569,
          0.020078118046987822,
          0.10294736396870857,
          0.03478569961098149,
          0.09037847712028986,
          0.1024752857333977,
          0.08477214876223454,
          0.09303252342527821,
          0.35972167431089164,
          0.6269964320535054,
          0.02229771934306511,
          0.12815988863381383,
          0.9044104743866666,
          0.09939450534256664,
          0.08368390019618643,
          0.6156204658055382,
          0.10299003317404899,
          0.3923523229111398,
          0.02910436017706571,
          0.3051248744914812,
          0.04333963376370318,
          0.04301747342480935,
          0.2518085341864779,
          0.26143261820034946,
          0.1279324824188678,
          0.12616604101537487,
          0.46987367283587683,
          0.18533375241769465,
          0.8942342312481485,
          0.30521803429055244
         ]
        },
        {
         "marker": {
          "color": "#006561"
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          0,
          0.02564102564102564,
          0.05128205128205128,
          0.07692307692307693,
          0.10256410256410256,
          0.1282051282051282,
          0.15384615384615385,
          0.1794871794871795,
          0.20512820512820512,
          0.23076923076923075,
          0.2564102564102564,
          0.28205128205128205,
          0.3076923076923077,
          0.3333333333333333,
          0.358974358974359,
          0.3846153846153846,
          0.41025641025641024,
          0.4358974358974359,
          0.4615384615384615,
          0.48717948717948717,
          0.5128205128205128,
          0.5384615384615385,
          0.5641025641025641,
          0.5897435897435898,
          0.6153846153846154,
          0.641025641025641,
          0.6666666666666667,
          0.6923076923076923,
          0.717948717948718,
          0.7435897435897436,
          0.7692307692307693,
          0.7948717948717949,
          0.8205128205128205,
          0.8461538461538461,
          0.8717948717948718,
          0.8974358974358975,
          0.9230769230769231,
          0.9487179487179487,
          0.9743589743589743,
          1
         ],
         "y": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ]
        },
        {
         "marker": {
          "color": "#006561"
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          0.14,
          0.16606060606060608,
          0.19212121212121214,
          0.2181818181818182,
          0.24424242424242426,
          0.2703030303030303,
          0.2963636363636364,
          0.32242424242424245,
          0.3484848484848485,
          0.37454545454545457,
          0.40060606060606063,
          0.4266666666666667,
          0.45272727272727276,
          0.4787878787878788,
          0.5048484848484849,
          0.530909090909091,
          0.556969696969697,
          0.583030303030303,
          0.6090909090909091,
          0.6351515151515151,
          0.6612121212121211,
          0.6872727272727273,
          0.7133333333333334,
          0.7393939393939394,
          0.7654545454545454,
          0.7915151515151515,
          0.8175757575757576,
          0.8436363636363636,
          0.8696969696969696,
          0.8957575757575758,
          0.9218181818181819,
          0.9478787878787879,
          0.9739393939393939,
          1
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "marker": {
          "color": "#006561"
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ],
         "y": [
          0.07142857142857144,
          0.09722222222222224,
          0.12301587301587302,
          0.14880952380952384,
          0.17460317460317462,
          0.2003968253968254,
          0.22619047619047622,
          0.25198412698412703,
          0.2777777777777778,
          0.3035714285714286,
          0.3293650793650794,
          0.35515873015873023,
          0.380952380952381,
          0.4067460317460318,
          0.4325396825396826,
          0.45833333333333337,
          0.4841269841269842,
          0.509920634920635,
          0.5357142857142857,
          0.5615079365079365,
          0.5873015873015872,
          0.6130952380952381,
          0.6388888888888888,
          0.6646825396825397,
          0.6904761904761905,
          0.7162698412698412,
          0.7420634920634921,
          0.7678571428571428,
          0.7936507936507936,
          0.8194444444444444,
          0.8452380952380952,
          0.871031746031746,
          0.8968253968253969,
          0.9226190476190477,
          0.9484126984126984,
          0.9742063492063492,
          1
         ]
        },
        {
         "marker": {
          "color": "#006561"
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "y": [
          0,
          0.02564102564102564,
          0.05128205128205128,
          0.07692307692307693,
          0.10256410256410256,
          0.1282051282051282,
          0.15384615384615385,
          0.1794871794871795,
          0.20512820512820512,
          0.23076923076923075,
          0.2564102564102564,
          0.28205128205128205,
          0.3076923076923077,
          0.3333333333333333,
          0.358974358974359,
          0.3846153846153846,
          0.41025641025641024,
          0.4358974358974359,
          0.4615384615384615,
          0.48717948717948717,
          0.5128205128205128,
          0.5384615384615385,
          0.5641025641025641,
          0.5897435897435898,
          0.6153846153846154,
          0.641025641025641,
          0.6666666666666667,
          0.6923076923076923,
          0.717948717948718,
          0.7435897435897436,
          0.7692307692307693,
          0.7948717948717949,
          0.8205128205128205,
          0.8461538461538461,
          0.8717948717948718,
          0.8974358974358975,
          0.9230769230769231,
          0.9487179487179487,
          0.9743589743589743,
          1
         ]
        },
        {
         "marker": {
          "color": "black"
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          0.14,
          0.1395218290209338,
          0.13809058247638115,
          0.13571603723150627,
          0.13241441383808886,
          0.12820826573170804,
          0.12312632516890848,
          0.117203306956754,
          0.11047967131549512,
          0.10300134749423843,
          0.09481942002760377,
          0.0859897797765535,
          0.07657274213713977,
          0.06663263502519032,
          0.05623735945141574,
          0.045457925688655705,
          0.0343679681997119,
          0.02304324263930276,
          0.011561108366126536,
          8.572527594031473e-18
         ],
         "y": [
          0,
          0.005898524676595167,
          0.011756756448623852,
          0.017534677652914225,
          0.023192819228905964,
          0.028692530332354964,
          0.03399624235979097,
          0.03906772558017335,
          0.043872336620690566,
          0.04837725511612436,
          0.05255170790522369,
          0.05636717924259955,
          0.059797605590180616,
          0.06281955365760637,
          0.06541238047536126,
          0.0675583744071882,
          0.0692428761385236,
          0.07045437881448018,
          0.07118460664333356,
          0.07142857142857144
         ]
        }
       ],
       "layout": {
        "height": 400,
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "scatter": [
           {
            "type": "scatter"
           }
          ]
         }
        },
        "width": 400,
        "xaxis": {
         "visible": false
        },
        "yaxis": {
         "scaleanchor": "x",
         "visible": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR, ExponentialLR\n",
    "import numpy as np\n",
    "from scipy.stats import qmc\n",
    "from plotly.express.colors import sequential\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "from global_constants import L, R, MU, LBD, N1, N2\n",
    "\n",
    "from new_plate_elliptic_hole import Plate \n",
    "\n",
    "# Elliptical axis in x direction\n",
    "Rx = 0.14\n",
    "Ry = R**2 / Rx\n",
    "# Edge samples\n",
    "N = 40\n",
    "# Number of collocation points\n",
    "M = 500\n",
    "\n",
    "# Epochs\n",
    "epochs = 4000\n",
    "# second epochs for second optimizer\n",
    "epochs2 = 50\n",
    "# Batch size\n",
    "batch_size = 64\n",
    "# Learning rate\n",
    "lr = lr = 0.005\n",
    "# Scheduler step width\n",
    "scheduler_step = 500\n",
    "# Gamma factor of scheduler\n",
    "scheduler_gamma = 0.6\n",
    "# Number of hidden neurons\n",
    "hn = 20\n",
    "# Weight of PDE lossWeight_NEU: 1.8841683879627231e-06, Weight_PDE: 3.1355081392423563e-06\n",
    "W_PDE = 6.45e-06 #previous value -> 3.14e-06\n",
    "# Weight of Neumann loss\n",
    "W_NEU = 8.37e-06 #previous value -> 1.88e-06\n",
    "# Weight of data losses\n",
    "W_STRESS = 1.5e-05\n",
    "W_DISP = 0.0\n",
    "\n",
    "\n",
    "def generate_radii_list(min_Ra_x, max_Ra_x, step):\n",
    "    num_steps = int((max_Ra_x - min_Ra_x) / step) + 1\n",
    "    rad_x_list = np.linspace(min_Ra_x, max_Ra_x, num_steps)\n",
    "    rad_x_list = [round(rad_x, 2) for rad_x in rad_x_list]\n",
    "    rad_y_list = []\n",
    "    for rad_x in rad_x_list:\n",
    "        rad_y_list.append(R**2 / rad_x)\n",
    "    return rad_x_list, rad_y_list\n",
    "\n",
    "def generate_multiple_plates_dict(min_Ra_x, max_Ra_x, iteration):\n",
    "    dict_plate_points = dict()\n",
    "    tuples = [\n",
    "            (\"x_collo\", 0, 0),\n",
    "            (\"y_collo\", 0, 1),\n",
    "            (\"x_top\", 1, 0),\n",
    "            (\"y_top\", 1, 1),\n",
    "            (\"x_right\", 2, 0),\n",
    "            (\"y_right\", 2, 1),\n",
    "            (\"x_left\", 3, 0),\n",
    "            (\"y_left\", 3, 1),\n",
    "            (\"x_bottom\", 4, 0),\n",
    "            (\"y_bottom\", 4, 1),\n",
    "            (\"x_hole\", 5, 0),\n",
    "            (\"y_hole\", 5, 1),   \n",
    "        ] \n",
    "    \n",
    "    rad_x_list, rad_y_list = generate_radii_list(min_Ra_x, max_Ra_x, 0.01)\n",
    "    for rad_x in rad_x_list:\n",
    "        p1 = Plate(rad_x, N, M)\n",
    "        #data_one_plate -> [collocation, top, right, left, bottom, hole, n_hole]\n",
    "        data_one_plate = p1.generate_dataset()\n",
    "        for tuple in tuples:\n",
    "            key = tuple[0]\n",
    "            dict_plate_points.setdefault(key, []).append(data_one_plate[tuple[1]][:,tuple[2]])\n",
    "        #plotting one plate\n",
    "        #p1.plot_plate_with_hole(*data_one_plate)\n",
    "    for key in dict_plate_points: \n",
    "        #appending list of tensors to one tensor\n",
    "        dict_plate_points[key] = torch.cat(dict_plate_points[key])\n",
    "        print(key, \"besteht aus\",dict_plate_points[key].size(), \"Datenpunkten\")\n",
    "\n",
    "    collo_points = torch.column_stack([dict_plate_points[\"x_collo\"], dict_plate_points[\"y_collo\"]])\n",
    "    top_points = torch.column_stack([dict_plate_points[\"x_top\"], dict_plate_points[\"y_top\"]])\n",
    "    right_points = torch.column_stack([dict_plate_points[\"x_right\"], dict_plate_points[\"y_right\"]])\n",
    "    left_points = torch.column_stack([dict_plate_points[\"x_left\"], dict_plate_points[\"y_left\"]])\n",
    "    bottom_points = torch.column_stack([dict_plate_points[\"x_bottom\"], dict_plate_points[\"y_bottom\"]])\n",
    "    hole_points = torch.column_stack([dict_plate_points[\"x_hole\"], dict_plate_points[\"y_hole\"]])\n",
    "\n",
    "    return collo_points, top_points, right_points, left_points, bottom_points, hole_points\n",
    "\n",
    "#train_plates_data = generate_multiple_plates_dict(0.04, 0.18, 14)\n",
    "\n",
    "p99 = Plate(0.14, N, M)\n",
    "collocation, top, right, left, bottom, hole, n_hole = p99.generate_dataset()\n",
    "p99.plot_plate_with_hole(collocation, top, right, left, bottom, hole, n_hole)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ANN model that approximates the displacement field\n",
    "\n",
    "An ANN might be considered as a generic function approximator. In this case, it should approximated the function $u: \\mathcal{R}^2 \\rightarrow \\mathcal{R}^2$ with five hidden layers having 20 neurons each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_layer1 = torch.nn.Linear(2, hn)\n",
    "        self.hidden_layer2 = torch.nn.Linear(hn, hn)\n",
    "        self.hidden_layer3 = torch.nn.Linear(hn, hn)\n",
    "        self.hidden_layer4 = torch.nn.Linear(hn, hn)\n",
    "        self.hidden_layer5 = torch.nn.Linear(hn, hn)\n",
    "        self.output_layer = torch.nn.Linear(hn, 2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        layer1_out = torch.tanh(self.hidden_layer1(inputs))\n",
    "        layer2_out = torch.tanh(self.hidden_layer2(layer1_out))\n",
    "        layer3_out = torch.tanh(self.hidden_layer3(layer2_out))\n",
    "        layer4_out = torch.tanh(self.hidden_layer4(layer3_out))\n",
    "        layer5_out = torch.tanh(self.hidden_layer5(layer4_out))\n",
    "        output = self.output_layer(layer5_out)\n",
    "        return output\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "def reset_net_parameters(net):\n",
    "    for layer in net.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The physics\n",
    "\n",
    "We want to solve linear elasticity on the domain, which means ultimately that we want to minimize the residual of the following PDE \n",
    "$$\\frac{\\partial \\sigma_{11}}{\\partial x_1} + \\frac{\\partial \\sigma_{12}}{\\partial x_2} - b_1 = 0$$\n",
    "$$\\frac{\\partial \\sigma_{21}}{\\partial x_1} + \\frac{\\partial \\sigma_{22}}{\\partial x_2} - b_2 = 0$$\n",
    "with stress \n",
    "$$ \\sigma_{ij} = 2\\mu \\varepsilon_{ij} + \\lambda \\varepsilon_{kk} \\delta_{ij} $$\n",
    "and strain \n",
    "$$ \\varepsilon_{ij} = \\frac{1}{2} \\left( \\frac{\\partial u_i}{\\partial x_j} +  \\frac{\\partial u_j}{\\partial x_i}\\right).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon(x):\n",
    "    # Compute deformation gradient\n",
    "    dudx = torch.func.jacrev(net)(x)\n",
    "    return 0.5 * (dudx + dudx.T)\n",
    "\n",
    "def sigma(x):\n",
    "    # Compute (small deformation) strain\n",
    "    eps = epsilon(x)\n",
    "    # Compute linear elastic strain (assuming plane stress)\n",
    "    return 2.0 * MU * eps + (2*LBD*MU)/(2*MU+LBD) * torch.trace(eps) * torch.eye(2)\n",
    "\n",
    "\n",
    "def pde_residual(x):\n",
    "    # Compute stress gradient\n",
    "    dsdx = torch.func.jacrev(sigma)(x)\n",
    "    # Momentum balance in x direction\n",
    "    residual_x = dsdx[0, 0, 0] + dsdx[0, 1, 1] \n",
    "    # Momentum balance in y direction\n",
    "    residual_y = dsdx[1, 0, 0] + dsdx[1, 1, 1]\n",
    "    return residual_x, residual_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boundary conditions\n",
    "\n",
    "Left: \n",
    "\n",
    "$$ u_1 = 0$$\n",
    "\n",
    "Bottom: \n",
    "\n",
    "$$ u_2 = 0$$\n",
    "\n",
    "Top: \n",
    "\n",
    "$$ \\sigma \\cdot n = N_2 n$$\n",
    "\n",
    "Right: \n",
    "\n",
    "$$ \\sigma \\cdot n = N_1 n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "def compute_physics_losses(complete_collo):\n",
    "    # pde\n",
    "    res_x, res_y = torch.vmap(pde_residual)(complete_collo)\n",
    "    zeros = torch.zeros_like(res_x)\n",
    "    pde_error = mse((res_x), zeros) + mse((res_y), zeros)\n",
    "\n",
    "    # left boundary\n",
    "    pred_left = net(left)\n",
    "    bc_left = torch.zeros_like(pred_left[:, 0])\n",
    "    left_error = mse(pred_left[:, 0], bc_left)\n",
    "\n",
    "    # bottom boundary\n",
    "    pred_bottom = net(bottom)\n",
    "    bc_bottom = torch.zeros_like(pred_bottom[:, 1])\n",
    "    bottom_error = mse(pred_bottom[:, 1], bc_bottom)\n",
    "\n",
    "    # top boundary\n",
    "    pred_stress_top = torch.vmap(sigma)(top)\n",
    "    pred_s_top_yy = pred_stress_top[:,1,1]\n",
    "    pred_s_top_xy = pred_stress_top[:,0,1]\n",
    "    s_top_yy = N2*torch.ones_like(pred_s_top_yy)\n",
    "    s_top_xy = torch.zeros_like(pred_s_top_xy)\n",
    "    top_error = mse(pred_s_top_yy, s_top_yy) + mse(pred_s_top_xy, s_top_xy)\n",
    "\n",
    "    # right boundary\n",
    "    pred_stress_right = torch.vmap(sigma)(right)\n",
    "    pred_s_right_xx = pred_stress_right[:,0,0]\n",
    "    pred_s_right_xy = pred_stress_right[:,1,0]\n",
    "    s_right_xx = N1*torch.ones_like(pred_s_right_xx)\n",
    "    s_right_xy = torch.zeros_like(pred_s_right_xy)\n",
    "    right_error = mse(pred_s_right_xx, s_right_xx) + mse(pred_s_right_xy, s_right_xy)\n",
    "\n",
    "\n",
    "    # hole boundary\n",
    "    stress_hole = torch.vmap(sigma)(hole)\n",
    "    traction = torch.einsum(\"...ij,...j->...i\", stress_hole, n_hole)\n",
    "    zeros = torch.zeros_like(traction[:, 0])\n",
    "    hole_error = mse(traction[:, 0], zeros) + mse(traction[:, 1], zeros)\n",
    "\n",
    "\n",
    "    return (left_error, right_error, bottom_error, top_error, hole_error, pde_error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with Adam optimizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:12<00:00,  3.25it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_x: 0.04, Weight_NEU: 8.37e-06, Weight_PDE: 6.45e-06, Weight_STRESS: 1.5e-05, Stress Error: 277.4381615204689\n",
      "Starting with Adam optimizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:10<00:00,  3.65it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_x: 0.05, Weight_NEU: 8.37e-06, Weight_PDE: 6.45e-06, Weight_STRESS: 1.5e-05, Stress Error: 142.41752314080276\n",
      "Starting with Adam optimizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 35/40 [00:10<00:01,  3.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 105\u001b[0m\n\u001b[0;32m    102\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rad_x \u001b[38;5;129;01min\u001b[39;00m rad_x_list:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m#weights_optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     mse_error, data_hole, stress_hole, hole \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWeight_NEU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWeight_PDE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrad_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m#mse_error.backward()\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;66;03m#weights_optimizer.step()\u001b[39;00m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m#weights_scheduler.step()\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m#save net parameters\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(net\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet_param/net_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrad_x\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[50], line 45\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(Weight_NEU, Weight_PDE, rad_x)\u001b[0m\n\u001b[0;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Compute physics losses\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m left_l, right_l, bottom_l, top_l, hole_l, pde_l \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_physics_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m W_DISP \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1E-10\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m W_STRESS \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1E-10\u001b[39m:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# No data losses needed (we can accelerate training by skipping this part)\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     stress_l \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "Cell \u001b[1;32mIn[49], line 29\u001b[0m, in \u001b[0;36mcompute_physics_losses\u001b[1;34m(complete_collo)\u001b[0m\n\u001b[0;32m     26\u001b[0m top_error \u001b[38;5;241m=\u001b[39m mse(pred_s_top_yy, s_top_yy) \u001b[38;5;241m+\u001b[39m mse(pred_s_top_xy, s_top_xy)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# right boundary\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m pred_stress_right \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m pred_s_right_xx \u001b[38;5;241m=\u001b[39m pred_stress_right[:,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     31\u001b[0m pred_s_right_xy \u001b[38;5;241m=\u001b[39m pred_stress_right[:,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\_functorch\\vmap.py:434\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[0;32m    431\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[1;32m--> 434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _flat_vmap(\n\u001b[0;32m    435\u001b[0m     func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    436\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\_functorch\\vmap.py:39\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[1;32m---> 39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\_functorch\\vmap.py:619\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[1;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    618\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[1;32m--> 619\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39mbatched_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[48], line 8\u001b[0m, in \u001b[0;36msigma\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msigma\u001b[39m(x):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Compute (small deformation) strain\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     eps \u001b[38;5;241m=\u001b[39m \u001b[43mepsilon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Compute linear elastic strain (assuming plane stress)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m MU \u001b[38;5;241m*\u001b[39m eps \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mLBD\u001b[38;5;241m*\u001b[39mMU)\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mMU\u001b[38;5;241m+\u001b[39mLBD) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtrace(eps) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[48], line 3\u001b[0m, in \u001b[0;36mepsilon\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mepsilon\u001b[39m(x):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Compute deformation gradient\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     dudx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjacrev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (dudx \u001b[38;5;241m+\u001b[39m dudx\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\_functorch\\eager_transforms.py:598\u001b[0m, in \u001b[0;36mjacrev.<locals>.wrapper_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    596\u001b[0m     flat_jacobians_per_input \u001b[38;5;241m=\u001b[39m compute_jacobian_preallocate_and_copy()\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 598\u001b[0m     flat_jacobians_per_input \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_jacobian_stacked\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;66;03m# Step 2: The returned jacobian is one big tensor per input. In this step,\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;66;03m# we split each Tensor by output.\u001b[39;00m\n\u001b[0;32m    602\u001b[0m flat_jacobians_per_input \u001b[38;5;241m=\u001b[39m [result\u001b[38;5;241m.\u001b[39msplit(flat_output_numels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m flat_jacobians_per_input]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\_functorch\\eager_transforms.py:529\u001b[0m, in \u001b[0;36mjacrev.<locals>.wrapper_fn.<locals>.compute_jacobian_stacked\u001b[1;34m()\u001b[0m\n\u001b[0;32m    527\u001b[0m     chunked_result \u001b[38;5;241m=\u001b[39m vjp_fn(basis)\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# chunk_size is None or chunk_size != 1\u001b[39;00m\n\u001b[1;32m--> 529\u001b[0m     chunked_result \u001b[38;5;241m=\u001b[39m \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvjp_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m flat_results, _ \u001b[38;5;241m=\u001b[39m tree_flatten(chunked_result)\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\_functorch\\vmap.py:434\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[0;32m    431\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[1;32m--> 434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _flat_vmap(\n\u001b[0;32m    435\u001b[0m     func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    436\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\_functorch\\vmap.py:39\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[1;32m---> 39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\_functorch\\vmap.py:619\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[1;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    618\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[1;32m--> 619\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39mbatched_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\_functorch\\eager_transforms.py:325\u001b[0m, in \u001b[0;36m_vjp_with_argnums.<locals>.wrapper\u001b[1;34m(cotangents, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m primals_out_spec \u001b[38;5;241m!=\u001b[39m cotangents_spec:\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected pytree structure of cotangents to be the same \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mas pytree structure of outputs to the function. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcotangents: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtreespec_pprint(cotangents_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprimal output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtreespec_pprint(primals_out_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 325\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_autograd_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_primals_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_diff_primals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_cotangents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(result, primals_spec)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\_functorch\\eager_transforms.py:113\u001b[0m, in \u001b[0;36m_autograd_grad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(diff_outputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(torch\u001b[38;5;241m.\u001b[39mzeros_like(inp) \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[1;32m--> 113\u001b[0m grad_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiff_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m grad_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(torch\u001b[38;5;241m.\u001b[39mzeros_like(inp) \u001b[38;5;28;01mif\u001b[39;00m gi \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gi\n\u001b[0;32m    118\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m gi, inp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(grad_inputs, inputs))\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_inputs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\autograd\\__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "scheduler = StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.999)\n",
    "loss_history = []\n",
    "weight_history = []\n",
    "\n",
    "#Weight_NEU and Weight_PDE as PyTorch nn parameter \n",
    "Weight_NEU = torch.nn.Parameter(torch.tensor(W_NEU), requires_grad=True) #previous value -> 6.4531255763296895e-06\n",
    "Weight_PDE = torch.nn.Parameter(torch.tensor(W_PDE), requires_grad=True) #previous value -> 8.376708219353885e-06\n",
    "Weight_STRESS = torch.nn.Parameter(torch.tensor(W_STRESS), requires_grad=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def training(Weight_NEU, Weight_PDE, rad_x):\n",
    "\n",
    "    p1 = Plate(rad_x, N, M) \n",
    "    data_input, data_output, data_hole = p1.load_reference_data()\n",
    "    collocation, top, right, left, bottom, hole, n_hole = p1.generate_dataset()\n",
    "    data_hole = data_hole.numpy()\n",
    "    data_hole = data_hole[data_hole[:, 0].argsort()]\n",
    "    data_stress_x = data_hole[:, 2]\n",
    "    data_stress_y = data_hole[:, 3]\n",
    "\n",
    "\n",
    "    #interpolate data_stress_x and data_stress_y\n",
    "    f_stress_x = interp1d(data_hole[:, 0], data_hole[:, 2], kind='cubic')\n",
    "    f_stress_y = interp1d(data_hole[:, 0], data_hole[:, 3], kind='cubic')\n",
    "    x_new = np.linspace(data_hole[:, 0][-1], data_hole[:, 0][0], hole[:, 0].size(dim=0))\n",
    "    y_stress_x = f_stress_x(x_new)\n",
    "    y_stress_y = f_stress_y(x_new)\n",
    "\n",
    "\n",
    "    print(\"Starting with Adam optimizer...\")\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Permutation to shuffle collocation points randomly in each epoch\n",
    "        permutation = torch.randperm(collocation.size()[0])\n",
    "\n",
    "        for i in range(0, collocation.size()[0], batch_size):\n",
    "            indices = permutation[i : i + batch_size]\n",
    "            collo = collocation[indices]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute physics losses\n",
    "            left_l, right_l, bottom_l, top_l, hole_l, pde_l = compute_physics_losses(collo)\n",
    "\n",
    "            if W_DISP < 1E-10 and W_STRESS < 1E-10:\n",
    "                # No data losses needed (we can accelerate training by skipping this part)\n",
    "                stress_l = 0.0\n",
    "                disp_l = 0.0\n",
    "            else:\n",
    "                # Get samples from reference solution\n",
    "                samples = torch.randperm(data_output.size()[0])[::100]\n",
    "                # Reference solutions\n",
    "                s_data = data_output[samples, 0:3]\n",
    "                e_data = data_output[samples, 4:7]\n",
    "                u_data = data_output[samples, 7:10]\n",
    "                # Predictions\n",
    "                s_pred = torch.vmap(sigma)(data_input[samples, 0:2])\n",
    "                e_pred = torch.vmap(epsilon)(data_input[samples, 0:2])\n",
    "                u_pred = net(data_input[samples, 0:2])\n",
    "                # Compute data losses\n",
    "                ds_xx = mse(s_data[:, 0], s_pred[:, 0, 0])\n",
    "                ds_yy = mse(s_data[:, 1], s_pred[:, 1, 1])\n",
    "                ds_xy = mse(s_data[:, 2], s_pred[:, 0, 1])\n",
    "                stress_l = ds_xx + ds_yy + ds_xy\n",
    "                du_x = mse(u_data[:, 0], u_pred[:, 0])\n",
    "                du_y = mse(u_data[:, 1], u_pred[:, 1])\n",
    "                disp_l = du_x + du_y\n",
    "\n",
    "            # Aggregate losses\n",
    "            dirichlet_losses = left_l + bottom_l \n",
    "            neumann_losses = right_l + top_l + hole_l\n",
    "            loss = (\n",
    "                dirichlet_losses\n",
    "                + Weight_NEU * neumann_losses\n",
    "                + Weight_PDE * pde_l\n",
    "                + W_STRESS * stress_l\n",
    "                + W_DISP * disp_l\n",
    "            )\n",
    "\n",
    "            # Make optimization step after batch\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Make scheduler step after full epoch\n",
    "        scheduler.step()\n",
    "        \n",
    "        # append loss to history (=for plotting)\n",
    "        with torch.autograd.no_grad():\n",
    "            loss_history.append(float(loss.data))\n",
    "\n",
    "    # compare computed stressError(PINN) with actual stressError\n",
    "    stress_hole = torch.vmap(sigma)(hole)\n",
    "    stressError = mse(stress_hole[:, 0, 0], torch.tensor(y_stress_x)) + mse(stress_hole[:, 1, 1], torch.tensor(y_stress_y))\n",
    "    return stressError, data_hole, stress_hole, hole\n",
    "\n",
    "\n",
    "# weights_optimizer = torch.optim.Adam([Weight_NEU, Weight_PDE], lr=1)\n",
    "# weights_scheduler = ExponentialLR(weights_optimizer, gamma=1)\n",
    "rad_x_list, _ = generate_radii_list(0.04, 0.18, 0.01)\n",
    "i = 0\n",
    "for rad_x in rad_x_list:\n",
    "    #weights_optimizer.zero_grad()\n",
    "    mse_error, data_hole, stress_hole, hole = training(Weight_NEU, Weight_PDE, rad_x)\n",
    "\n",
    "    #mse_error.backward()\n",
    "    #weights_optimizer.step()\n",
    "    #weights_scheduler.step()\n",
    "\n",
    "    #save net parameters\n",
    "    torch.save(net.state_dict(), f'net_param/net_{rad_x:.2f}.pth')\n",
    "\n",
    "\n",
    "    with torch.autograd.no_grad():\n",
    "        weight_history.append(float(mse_error.data))\n",
    "        #stress_hole = torch.vmap(sigma)(hole)\n",
    "        plt.figure(figsize=(5, 3))\n",
    "        plt.plot(hole[:, 0], stress_hole[:, 0, 0], \"o\", color=\"tab:blue\", label=\"_xx (PINN)\")\n",
    "        plt.plot(data_hole[:, 0], data_hole[:, 2], \"-\", color=\"tab:blue\", label=\"_xx (FEM)\")\n",
    "        plt.plot(hole[:, 0], stress_hole[:, 1, 1], \"o\", color=\"tab:orange\", label=\"_yy (PINN)\")\n",
    "        plt.plot(data_hole[:, 0], data_hole[:, 3], \"-\", color=\"tab:orange\", label=\"_yy (FEM)\")\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"Stress\")\n",
    "        #plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    # print weights and stress error \n",
    "    print(f\"R_x: {rad_x}, Weight_NEU: {Weight_NEU.item()}, Weight_PDE: {Weight_PDE.item()}, Weight_STRESS: {Weight_STRESS.item()}, Stress Error: {mse_error.item()}\") #, lr: {weights_optimizer.param_groups[0]['lr']}\")\n",
    "    \n",
    "    #reset net parameters\n",
    "    reset_net_parameters(net)\n",
    "    i += 1\n",
    "#plt.figure(figsize=(8, 4))\n",
    "plt.plot(loss_history, c='g', label='train', linewidth=2.0)\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Training\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "blue"
         },
         "mode": "markers",
         "name": "_xx (PINN)",
         "type": "scatter",
         "x": [
          0.18,
          0.17938520874120056,
          0.17754503461249002,
          0.17449204786907946,
          0.17024710350611422,
          0.1648391987979103,
          0.15830527521716803,
          0.15068996608725513,
          0.14204529169135083,
          0.13243030392116367,
          0.12191068289263339,
          0.1105582882841402,
          0.09845066846203684,
          0.08567053074667325,
          0.07230517643753451,
          0.05844590445684304,
          0.04418738768534386,
          0.029627026250532113,
          0.01486428218501983,
          1.1021821192326179e-17
         ],
         "y": [
          -0.6046762517953658,
          -0.6054885157335946,
          -0.6067379912611642,
          -0.6084130323896804,
          -0.6104990759942615,
          -0.612978748084896,
          -0.6158319764470306,
          -0.6190361139141735,
          -0.6225660771353387,
          -0.6263945058878861,
          -0.6304919477244917,
          -0.6348270720120031,
          -0.6393669162239135,
          -0.644077165720675,
          -0.6489224662611586,
          -0.6538667662387767,
          -0.6588736832668853,
          -0.6639068874185456,
          -0.6689304913421195,
          -0.6739094358156827
         ]
        },
        {
         "marker": {
          "color": "blue"
         },
         "mode": "lines",
         "name": "_xx (FEM)",
         "type": "scatter",
         "x": [
          0.0010673038127123106,
          0.00473453713301016,
          0.008400922510452219,
          0.010534257716176346,
          0.014197944566557362,
          0.01785905388866409,
          0.019988521099285915,
          0.023644124216773525,
          0.02729531571931644,
          0.029418163071154364,
          0.03306081557985114,
          0.03669703750811057,
          0.038810236750148046,
          0.04243451901582529,
          0.04605006642324955,
          0.04815016181040915,
          0.051749820171807556,
          0.0553380255503683,
          0.05742094163116744,
          0.060988524344373324,
          0.06454134550021529,
          0.06660212348238792,
          0.07012846882715852,
          0.07363590096969654,
          0.07566832184393996,
          0.07914182220595864,
          0.08259104155641533,
          0.08458706961966783,
          0.08799256841636217,
          0.09136663563395832,
          0.09331557253665435,
          0.0966326746000179,
          0.09990852915274892,
          0.10179569879768645,
          0.10499612305606225,
          0.10814141289753135,
          0.10994606794879144,
          0.11298940098620036,
          0.11595736841575588,
          0.1176492925106275,
          0.12047612643345154,
          0.12319741381125511,
          0.12473150809977046,
          0.1272529423668151,
          0.12962362369245337,
          0.1309321504982981,
          0.13301635645076676,
          0.13488496922296933,
          0.1358701121492429,
          0.1373356076277383,
          0.13850599415065462,
          0.139046664833113,
          0.13969378415760225,
          0.13998304530122588
         ],
         "y": [
          6.112019833538571,
          6.110818371128158,
          6.106324373519167,
          6.1031399605765495,
          6.0959611643457166,
          6.085449301652819,
          6.079126103278414,
          6.065465411572772,
          6.0483464987424185,
          6.038695802512617,
          6.018223002314917,
          5.994090269536221,
          5.980370575090332,
          5.9521976278130575,
          5.9201049954365725,
          5.90226428291853,
          5.8651126797859225,
          5.823627871310517,
          5.800498602048085,
          5.752819547852847,
          5.700323057725887,
          5.670444956431346,
          5.6102811742892245,
          5.544650279078072,
          5.506639090715515,
          5.430791443529117,
          5.348399782951468,
          5.300372977905292,
          5.204496471716831,
          5.100605440519777,
          5.038288601209295,
          4.916637584532895,
          4.785070986725522,
          4.7028665490917465,
          4.548405349959075,
          4.381349917369009,
          4.2740853810335855,
          4.077648309069913,
          3.8645225687036904,
          3.7150407367331972,
          3.468314195801754,
          3.2008902909708215,
          3.000554813394251,
          2.7031414187830127,
          2.3776937609268343,
          2.1174916278391698,
          1.7848259852550008,
          1.414098431382812,
          1.150359653009927,
          0.8441616045419216,
          0.48574825821850465,
          0.35546595381612933,
          0.18806874689981834,
          -0.03941432866304595
         ]
        },
        {
         "marker": {
          "color": "orange"
         },
         "mode": "markers",
         "name": "_yy (PINN)",
         "type": "scatter",
         "x": [
          0.18,
          0.17938520874120056,
          0.17754503461249002,
          0.17449204786907946,
          0.17024710350611422,
          0.1648391987979103,
          0.15830527521716803,
          0.15068996608725513,
          0.14204529169135083,
          0.13243030392116367,
          0.12191068289263339,
          0.1105582882841402,
          0.09845066846203684,
          0.08567053074667325,
          0.07230517643753451,
          0.05844590445684304,
          0.04418738768534386,
          0.029627026250532113,
          0.01486428218501983,
          1.1021821192326179e-17
         ],
         "y": [
          -0.5613267820808667,
          -0.5619503578478005,
          -0.5628041784207065,
          -0.5638805887783362,
          -0.5651702498316011,
          -0.56666221451443,
          -0.5683440150943481,
          -0.570201763349148,
          -0.5722202651849474,
          -0.574383150993241,
          -0.57667302256309,
          -0.5790716166944196,
          -0.5815599848280637,
          -0.5841186870597643,
          -0.5867279978941786,
          -0.5893681200873588,
          -0.5920194019963032,
          -0.5946625530789431,
          -0.5972788516410306,
          -0.5998503386717624
         ]
        },
        {
         "marker": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "_yy (FEM)",
         "type": "scatter",
         "x": [
          0.0010673038127123106,
          0.00473453713301016,
          0.008400922510452219,
          0.010534257716176346,
          0.014197944566557362,
          0.01785905388866409,
          0.019988521099285915,
          0.023644124216773525,
          0.02729531571931644,
          0.029418163071154364,
          0.03306081557985114,
          0.03669703750811057,
          0.038810236750148046,
          0.04243451901582529,
          0.04605006642324955,
          0.04815016181040915,
          0.051749820171807556,
          0.0553380255503683,
          0.05742094163116744,
          0.060988524344373324,
          0.06454134550021529,
          0.06660212348238792,
          0.07012846882715852,
          0.07363590096969654,
          0.07566832184393996,
          0.07914182220595864,
          0.08259104155641533,
          0.08458706961966783,
          0.08799256841636217,
          0.09136663563395832,
          0.09331557253665435,
          0.0966326746000179,
          0.09990852915274892,
          0.10179569879768645,
          0.10499612305606225,
          0.10814141289753135,
          0.10994606794879144,
          0.11298940098620036,
          0.11595736841575588,
          0.1176492925106275,
          0.12047612643345154,
          0.12319741381125511,
          0.12473150809977046,
          0.1272529423668151,
          0.12962362369245337,
          0.1309321504982981,
          0.13301635645076676,
          0.13488496922296933,
          0.1358701121492429,
          0.1373356076277383,
          0.13850599415065462,
          0.139046664833113,
          0.13969378415760225,
          0.13998304530122588
         ],
         "y": [
          -0.0012046555838474138,
          0.003507233028262391,
          0.00709674027927143,
          0.009625249897712296,
          0.019416632416835,
          0.028084785413913238,
          0.03377761581979222,
          0.04973264019716028,
          0.06450789551806224,
          0.07346760946655095,
          0.09632322957723871,
          0.11790333662980323,
          0.1304006665735402,
          0.16111048406785056,
          0.19038699600771203,
          0.20617938134709135,
          0.2463144644179327,
          0.28482827485726503,
          0.30501754418598814,
          0.3562073463813753,
          0.4053862152948118,
          0.4306354943944868,
          0.49538696257849235,
          0.5575795945310968,
          0.5910207987686977,
          0.671753633530654,
          0.7493899217663569,
          0.792756803436232,
          0.8944810778361001,
          0.992240819338861,
          1.0478540898416,
          1.177460875234031,
          1.3013407359552986,
          1.374706956078553,
          1.5404955166281598,
          1.697751006601426,
          1.7964802669932967,
          2.010566220716108,
          2.2118025336372233,
          2.3430631668309054,
          2.6136473445192676,
          2.861598797498497,
          3.0364477697157986,
          3.3732921536073035,
          3.67136943372706,
          3.8994133471797565,
          4.285953857323133,
          4.605638774384163,
          4.859133036224366,
          5.223966370666638,
          5.4833888922724086,
          5.659053650612934,
          5.86252330168238,
          5.924327552828249
         ]
        }
       ],
       "layout": {
        "height": 400,
        "showlegend": true,
        "template": {
         "data": {
          "scatter": [
           {
            "type": "scatter"
           }
          ]
         }
        },
        "title": {
         "text": "Stress at hole"
        },
        "width": 600
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stress_hole = torch.vmap(sigma)(hole)\n",
    "data_hole = np.loadtxt(f\"data/hole_Rx={Rx}.csv\", delimiter=\",\")\n",
    "data_hole = data_hole[data_hole[:, 0].argsort()]\n",
    "\n",
    "with torch.no_grad():\n",
    "    fig = go.Figure()\n",
    "    m1 = dict(color=\"blue\")\n",
    "    m2 = dict(color=\"orange\")\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=hole[:, 0],\n",
    "            y=stress_hole[:, 0, 0],\n",
    "            marker=m1,\n",
    "            mode=\"markers\",\n",
    "            name=\"_xx (PINN)\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=data_hole[:, 0],\n",
    "            y=data_hole[:, 2],\n",
    "            marker=m1,\n",
    "            mode=\"lines\",\n",
    "            name=\"_xx (FEM)\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=hole[:, 0],\n",
    "            y=stress_hole[:, 1, 1],\n",
    "            marker=m2,\n",
    "            mode=\"markers\",\n",
    "            name=\"_yy (PINN)\",\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=data_hole[:, 0],\n",
    "            y=data_hole[:, 3],\n",
    "            marker=m2,\n",
    "            mode=\"lines\",\n",
    "            name=\"_yy (FEM)\",\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        template=\"none\", width=600, height=400, title=\"Stress at hole\", showlegend=True\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 49\u001b[0m\n\u001b[0;32m     45\u001b[0m     fig\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Compute data error\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m s_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata_output\u001b[49m[:, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m     50\u001b[0m s_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvmap(sigma)(data_input[:, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     51\u001b[0m ds_xx \u001b[38;5;241m=\u001b[39m s_data[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m s_pred[:, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_output' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a validation domain different from the training domain\n",
    "val_x, val_y = np.meshgrid(np.linspace(0, L, 50), np.linspace(0, L, 50))\n",
    "val_domain = np.vstack([val_x.ravel(), val_y.ravel()]).T\n",
    "mask = (\n",
    "    ((val_domain[:, 0] ** 2) / (Rx**2)) + ((val_domain[:, 1] ** 2) / (Ry**2))\n",
    ") > 1\n",
    "val = torch.tensor(val_domain[mask], requires_grad=True).double()\n",
    "\n",
    "# Compute model predictions on the validation domain\n",
    "disp = net(val)\n",
    "def_val = val + disp\n",
    "stress = torch.vmap(sigma)(val)\n",
    "mises = torch.sqrt(\n",
    "    stress[:, 0, 0] ** 2\n",
    "    + stress[:, 1, 1] ** 2\n",
    "    - stress[:, 0, 0] * stress[:, 1, 1]\n",
    "    + 3 * stress[:, 0, 1] ** 2\n",
    ")\n",
    "# print([loss.item() for loss in compute_les(val)])\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def make_plot(x, y, variable, title, cmap=sequential.Viridis, size=8.0):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Plot boundaries\n",
    "    m = dict(color=\"black\")\n",
    "    fig.add_trace(go.Scatter(x=top[:, 0], y=top[:, 1], mode=\"lines\", marker=m))\n",
    "    fig.add_trace(go.Scatter(x=bottom[:, 0], y=bottom[:, 1], mode=\"lines\", marker=m))\n",
    "    fig.add_trace(go.Scatter(x=left[:, 0], y=left[:, 1], mode=\"lines\", marker=m))\n",
    "    fig.add_trace(go.Scatter(x=right[:, 0], y=right[:, 1], mode=\"lines\", marker=m))\n",
    "    fig.add_trace(go.Scatter(x=hole[:, 0], y=hole[:, 1], mode=\"lines\", marker=m))\n",
    "\n",
    "    # Plot variable values\n",
    "    m = dict(color=variable, colorscale=cmap, size=size, colorbar=dict(thickness=10))\n",
    "    fig.add_trace(go.Scatter(x=x, y=y, marker=m, mode=\"markers\"))\n",
    "\n",
    "    # plot settings\n",
    "    fig.layout.yaxis.scaleanchor = \"x\"\n",
    "    fig.update_layout(\n",
    "        template=\"none\", width=400, height=400, title=title, showlegend=False\n",
    "    )\n",
    "    fig.update_xaxes(visible=False)\n",
    "    fig.update_yaxes(visible=False)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Compute data error\n",
    "s_data = data_output[:, 0:3]\n",
    "s_pred = torch.vmap(sigma)(data_input[:, 0:2])\n",
    "ds_xx = s_data[:, 0] - s_pred[:, 0, 0]\n",
    "ds_yy = s_data[:, 1] - s_pred[:, 1, 1]\n",
    "ds_xy = s_data[:, 2] - s_pred[:, 0, 1]\n",
    "\n",
    "\n",
    "# Plot stress errors\n",
    "cmap = sequential.RdBu_r\n",
    "make_plot(*data_input[:, 0:2].T, ds_xx, \"Stress error xx\", size=2.0, cmap=cmap)\n",
    "make_plot(*data_input[:, 0:2].T, ds_yy, \"Stress error yy\", size=2.0, cmap=cmap)\n",
    "make_plot(*data_input[:, 0:2].T, ds_xy, \"Stress error xy\", size=2.0, cmap=cmap)\n",
    "\n",
    "# Plot stresses\n",
    "make_plot(*def_val.T, stress[:, 0, 0], \"Stress xx\")\n",
    "make_plot(*def_val.T, stress[:, 0, 1], \"Stress xy\")\n",
    "make_plot(*def_val.T, stress[:, 1, 1], \"Stress yy\")\n",
    "make_plot(*def_val.T, mises, \"Mises stress\")\n",
    "\n",
    "# Plot displacements\n",
    "make_plot(*def_val.T, disp[:, 0], \"Displacement in x\", cmap=sequential.Inferno)\n",
    "make_plot(*def_val.T, disp[:, 1], \"Displacement in y\", cmap=sequential.Inferno)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "578dd1749cd7a4cd4ca9aa2aa31ddd8a39c768a81580b28f257ef59bc72538ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
