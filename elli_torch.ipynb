{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple PINN for an elastic plate with a hole "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the data and build the neural network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import functorch\n",
    "import numpy as np\n",
    "from scipy.stats import qmc\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from math import pi, ceil\n",
    "from plate_elliptic_hole import Plate \n",
    "\n",
    "from global_constants import L, R, B0, EPS0, MU, LBD, RATIO\n",
    "\n",
    "# Applied strain at right boundary\n",
    "EPS0 = 0.1\n",
    "# Applied body force field\n",
    "B0 = 0.0\n",
    "# Lame constants\n",
    "MU = 1\n",
    "LBD = 2\n",
    "\n",
    "Ra_x = 0.7 #radius on the x-axis of the ellipse \n",
    "SuAr= 0.25*pi   #surface area of the eclipse (= equal to SuAr of a circle with R=0.5)\n",
    "Min_Ra_x = 0.25\n",
    "Max_Ra_x = 0.8\n",
    "# Min_Ra_x_train = 0.5 #minimal radius on the x-axis of the ellipse\n",
    "# Max_Ra_x_train = 0.8 #maximum radius on the x-axis of the ellipse\n",
    "# Min_Ra_x_test = 0.25 #minimal radius on the x-axis of the ellipse\n",
    "# Max_Ra_x_test = 0.5 #maximum radius on the x-axis of the ellipse\n",
    "\n",
    "L = 1 #length of plate #info: muss noch gefixt werden -> momentan bei 1 lassen\n",
    "N = 15 #15 #number of collocation Point in x-axis direction\n",
    "P = 20 #number of plates in dataset\n",
    "NN = ceil(N * (L-Ra_x)/L) #number of collocation Point in both direction\n",
    "\n",
    "def generate_radii_list(iteration, min_Ra_x, max_Ra_x):\n",
    "    rad_x_list = np.linspace(min_Ra_x, max_Ra_x, iteration)\n",
    "    rad_y_list = []\n",
    "    for rad_x in rad_x_list:\n",
    "        rad_y_list.append(SuAr/(pi*rad_x))\n",
    "    return rad_x_list, rad_y_list\n",
    "\n",
    "def generate_multiple_plates_dict(iteration, min_Ra_x, max_Ra_x):\n",
    "    dict_plate_points = dict()\n",
    "    tuples = [\n",
    "            (\"x_collo\", 0, 0),\n",
    "            (\"y_collo\", 0, 1),\n",
    "            (\"r_collo\", 0, 2),\n",
    "            (\"x_top\", 1, 0),\n",
    "            (\"y_top\", 1, 1),\n",
    "            (\"r_top\", 1, 2),\n",
    "            (\"x_right\", 2, 0),\n",
    "            (\"y_right\", 2, 1),\n",
    "            (\"r_right\", 2, 2),\n",
    "            (\"x_left\", 3, 0),\n",
    "            (\"y_left\", 3, 1),\n",
    "            (\"r_left\", 3, 2),\n",
    "            (\"x_bottom\", 4, 0),\n",
    "            (\"y_bottom\", 4, 1),\n",
    "            (\"r_bottom\", 4, 2),\n",
    "            (\"x_hole\", 5, 0),\n",
    "            (\"y_hole\", 5, 1),\n",
    "            (\"n_hole\", 5, 2),\n",
    "            (\"r_hole\", 5, 3),\n",
    "            \n",
    "        ] \n",
    "    \n",
    "    ra_x_list, ra_y_list = generate_radii_list(iteration, min_Ra_x, max_Ra_x)\n",
    "    for i in range(iteration):\n",
    "        p1 = Plate(Ra_x, SuAr, L, N)\n",
    "        data_one_plate = p1.generate_dataset_new(ra_x_list[i], ra_y_list[i], L, N)\n",
    "        for tuple in tuples:\n",
    "            key = tuple[0]\n",
    "            dict_plate_points.setdefault(key, []).append(data_one_plate[tuple[1]][tuple[2]])\n",
    "        #p1.plot_plate_with_hole(*data_one_plate)\n",
    "    for key in dict_plate_points: \n",
    "        #print(key, \"  \",dict_plate_points[key])\n",
    "        #appending list of tensors to one tensor\n",
    "        dict_plate_points[key] = torch.cat(dict_plate_points[key])\n",
    "        if(key is not str(\"n_hole\")):\n",
    "            dict_plate_points[key] = torch.flatten(dict_plate_points[key])\n",
    "        #print(key, \"  \",dict_plate_points[key])\n",
    "        #print(key, \"shape is\", dict_plate_points[key].size())\n",
    "    #print(dict_plate_points)\n",
    "    #print(\"Der Datensatz besteht aus\",dict_plate_points[\"x_collo\"].size(), \"Datenpunkten\" )\n",
    "    #print(\"Der Datensatz besteht aus\",dict_plate_points[\"y_collo\"].size(), \"Datenpunkten\" )\n",
    "    #print(\"Der Datensatz besteht aus\",dict_plate_points[\"r_collo\"].size(), \"Datenpunkten\" )\n",
    "    collo_points = torch.column_stack([dict_plate_points[\"x_collo\"], dict_plate_points[\"y_collo\"], dict_plate_points[\"r_collo\"]])\n",
    "    top_points = torch.column_stack([dict_plate_points[\"x_top\"], dict_plate_points[\"y_top\"], dict_plate_points[\"r_top\"]])\n",
    "    right_points = torch.column_stack([dict_plate_points[\"x_right\"], dict_plate_points[\"y_right\"], dict_plate_points[\"r_right\"]])\n",
    "    left_points = torch.column_stack([dict_plate_points[\"x_left\"], dict_plate_points[\"y_left\"], dict_plate_points[\"r_left\"]])\n",
    "    bottom_points = torch.column_stack([dict_plate_points[\"x_bottom\"], dict_plate_points[\"y_bottom\"], dict_plate_points[\"r_bottom\"]])\n",
    "    hole_points = torch.column_stack([dict_plate_points[\"x_hole\"], dict_plate_points[\"y_hole\"], dict_plate_points[\"r_hole\"]])\n",
    "    n_hole = dict_plate_points[\"n_hole\"]\n",
    "\n",
    "    #shuffle points random\n",
    "    collo_points = collo_points[torch.randperm(collo_points.size()[0])]\n",
    "    top_points = top_points[torch.randperm(top_points.size()[0])]\n",
    "    right_points = right_points[torch.randperm(right_points.size()[0])]\n",
    "    left_points = left_points[torch.randperm(left_points.size()[0])]\n",
    "    bottom_points = bottom_points[torch.randperm(bottom_points.size()[0])]\n",
    "    hole_points = hole_points[torch.randperm(hole_points.size()[0])]\n",
    "\n",
    "\n",
    "    return collo_points, top_points, right_points, left_points, bottom_points, hole_points, n_hole\n",
    "\n",
    "\n",
    "p2 = Plate(Ra_x, SuAr, L, N)\n",
    "Re_xnew, Re_ynew = p2.create_ellipse(Ra_x,SuAr, L)\n",
    "#p2.plot_quarter_elli(Re_xnew, Re_ynew)\n",
    "train_plates_data = generate_multiple_plates_dict(P, Min_Ra_x, Max_Ra_x)\n",
    "test_plates_data = generate_multiple_plates_dict(P,Min_Ra_x, Max_Ra_x)\n",
    "#print(\"Der Datensatz besteht aus\", train_plates_data[1].shape, \"Datenpunkten\" )\n",
    "\n",
    "#data_train_points = p2.generate_dataset_test(Re_xnew, Re_ynew, L, N)\n",
    "#data_test_points = p2.generate_dataset_test(Re_xnew, Re_ynew, L, N)\n",
    "#p2.plot_plate_with_hole_old(*data_train_points)\n",
    "#p2.plot_plate_with_hole(*data_test_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        hn = 20\n",
    "        self.hidden_layer1 = torch.nn.Linear(3,hn)\n",
    "        self.hidden_layer2 = torch.nn.Linear(hn,hn)\n",
    "        self.hidden_layer3 = torch.nn.Linear(hn,hn)\n",
    "        self.hidden_layer4 = torch.nn.Linear(hn,hn)\n",
    "        self.hidden_layer5 = torch.nn.Linear(hn,hn)\n",
    "        self.output_layer = torch.nn.Linear(hn,2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        layer1_out = torch.tanh(self.hidden_layer1(inputs))\n",
    "        layer2_out = torch.tanh(self.hidden_layer2(layer1_out))\n",
    "        layer3_out = torch.tanh(self.hidden_layer3(layer2_out))\n",
    "        layer4_out = torch.tanh(self.hidden_layer4(layer3_out))\n",
    "        layer5_out = torch.tanh(self.hidden_layer5(layer4_out))\n",
    "        output = self.output_layer(layer5_out)\n",
    "        return output\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The physics\n",
    "\n",
    "We want to solve linear elasticity on the domain, which means ultimately that we want to minimize the residual of the PDE \n",
    "$$\n",
    "    \\nabla \\cdot \\sigma - \\mathbf{b} = \\mathbf{0}. \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(eps):\n",
    "    I = torch.eye(2)\n",
    "    return 2.0 * MU * eps + LBD * torch.einsum(\"...ii,...jk->...jk\", eps, I)\n",
    "\n",
    "def epsilon(x, y, r, net):\n",
    "    inputs = torch.column_stack([x,y,r])\n",
    "    disp = net(inputs)\n",
    "    u = disp[:,0]\n",
    "    v = disp[:,1]\n",
    "    u_x = torch.autograd.grad(u.sum(), x, create_graph=True)[0]\n",
    "    v_x = torch.autograd.grad(v.sum(), x, create_graph=True)[0]\n",
    "    u_y = torch.autograd.grad(u.sum(), y, create_graph=True)[0]\n",
    "    v_y = torch.autograd.grad(v.sum(), y, create_graph=True)[0]\n",
    "\n",
    "    gradx = torch.column_stack([u_x, v_x])\n",
    "    grady = torch.column_stack([u_y, v_y])\n",
    "    gradient = torch.stack([gradx, grady], dim=2)\n",
    "\n",
    "    return 0.5 * (gradient + torch.transpose(gradient, 1, 2))\n",
    "\n",
    "def pde_residual(x, y, r, net):\n",
    "    stress = sigma(epsilon(x,y,r, net))\n",
    "    sxx = stress[:,0,0]\n",
    "    sxy = stress[:,0,1]\n",
    "    syx = stress[:,1,0]\n",
    "    syy = stress[:,1,1]\n",
    "    \n",
    "\n",
    "    sxx_x = torch.autograd.grad(sxx.sum(), x, create_graph=True)[0]\n",
    "    sxy_y = torch.autograd.grad(sxy.sum(), y, create_graph=True)[0]\n",
    "    syx_x = torch.autograd.grad(syx.sum(), x, create_graph=True)[0]\n",
    "    syy_y = torch.autograd.grad(syy.sum(), y, create_graph=True)[0]\n",
    "\n",
    "    residual_x = sxx_x + sxy_y - B0\n",
    "    residual_y = syx_x + syy_y\n",
    "    return residual_x, residual_y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_PDE = 0.01\n",
    "W_NEUMANN = 0.01\n",
    "\n",
    "mse = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "def compute_loss(net, collo_points, top_points, right_points, left_points, bottom_points, hole_points, n_hole):\n",
    "\n",
    "    # pde\n",
    "    res_x, res_y = pde_residual(collo_points[:,0],collo_points[:,1],collo_points[:,2], net)\n",
    "    zeros = torch.zeros_like(res_x)\n",
    "    pde_error = mse(res_x, zeros) + mse(res_y, zeros)\n",
    "\n",
    "    # left boundary\n",
    "    pred_left = net(left_points)\n",
    "    bc_left = torch.zeros_like(pred_left[:,0])\n",
    "    left_error = mse(pred_left[:,0], bc_left) \n",
    "\n",
    "    # right boundary\n",
    "    pred_right = net(right_points)\n",
    "    bc_right = EPS0 * L * torch.ones_like(pred_right[:,0])\n",
    "    right_error = mse(pred_right[:,0], bc_right) \n",
    "\n",
    "    # bottom boundary\n",
    "    pred_bottom = net(bottom_points)\n",
    "    bc_bottom = torch.zeros_like(pred_bottom[:,1])\n",
    "    bottom_error = mse(pred_bottom[:,1], bc_bottom) \n",
    "\n",
    "    # top boundary\n",
    "    stress_top = sigma(epsilon(top_points[:,0],top_points[:,1],top_points[:,2], net))\n",
    "    #old top error\n",
    "    #zeros = torch.zeros_like(stress_top[:,1,1])\n",
    "    #top_error = mse(stress_top[:,1,1], zeros) + mse(stress_top[:,0,1], zeros)\n",
    "    #new top error\n",
    "    pred_top = net(top_points)\n",
    "    bc_top = RATIO * EPS0 * L * torch.ones_like(pred_top[:,1])\n",
    "    top_error = mse(pred_top[:,1], bc_top)\n",
    "\n",
    "    # hole boundary\n",
    "    stress_hole = sigma(epsilon(hole_points[:,0], hole_points[:,1], hole_points[:,2], net))\n",
    "    traction = torch.einsum(\"...ij,...j->...i\", stress_hole, n_hole)\n",
    "    zeros = torch.zeros_like(traction[:,0])\n",
    "    hole_error = mse(traction[:,0], zeros) + mse(traction[:,1], zeros)\n",
    "\n",
    "    return (\n",
    "        left_error\n",
    "        + right_error\n",
    "        + bottom_error\n",
    "        + top_error\n",
    "        + W_NEUMANN * hole_error\n",
    "        + W_PDE * pde_error\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: N: 15 plates: 20\n",
      "starting learning rate: 0.01 and gamma: 0.3 , epochs: 10000 iterations: 4\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR, ExponentialLR, StepLR, ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "net = Net()\n",
    "train_data = []\n",
    "test_data = []\n",
    "epochs = 10000\n",
    "iterations = 4\n",
    "epochs_per_iter = int(epochs/iterations)\n",
    "LeRa = 0.01\n",
    "gamma = 0.3\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "\n",
    "#\"\"\"\"\n",
    "optimizer = torch.optim.Adam(net.parameters(), LeRa)\n",
    "scheduler = StepLR(optimizer, step_size=epochs_per_iter, gamma= gamma)\n",
    "#train_data_loader = DataLoader(train_plates_data, batch_size = 7)\n",
    "#print(train_data_loader.dataset[6])\n",
    "#scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "\n",
    "#print(\"dataset: N:\", N, \"plates:\", P)\n",
    "#print(\"starting learning rate:\", LeRa, \"and gamma:\", gamma, \", epochs:\", epochs, \"iterations:\", iterations)\n",
    "# for epoch in range(epochs):\n",
    "#     for i in range(batch_size):\n",
    "#         #print(\"batch nr\", i+1)\n",
    "#         train_plates_data_batch = []\n",
    "#         test_plates_data_batch = []\n",
    "#         for data in train_plates_data:\n",
    "#             train_plates_data_batch.append(data[i+1::batch_size])\n",
    "#         for data in test_plates_data:\n",
    "#             test_plates_data_batch.append(data[i+1::batch_size])\n",
    "#             #print(len(data))\n",
    "#             #print(len(data[i+1::batch_size]))\n",
    "#             #print(len(train_plates_data_batch))\n",
    "#         optimizer.zero_grad()\n",
    "#         #old code\n",
    "#         #loss_train = compute_loss(net, *train_plates_data.values(), rad_x)\n",
    "#         #loss_test = compute_loss(net, *test_plates_data.values(), rad_x)\n",
    "#         #new code\n",
    "#         loss_train = compute_loss(net, *train_plates_data_batch)\n",
    "#         loss_test = compute_loss(net, *test_plates_data_batch)\n",
    "#         loss_train.backward(retain_graph=True)\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "#         #print(scheduler.get_lr())\n",
    "#         with torch.autograd.no_grad():\n",
    "#             train_data.append(float(loss_train.data))\n",
    "#             test_data.append(float(loss_test.data)) \n",
    "\n",
    "\n",
    "print(\"dataset: N:\", N, \"plates:\", P)\n",
    "print(\"starting learning rate:\", LeRa, \"and gamma:\", gamma, \", epochs:\", epochs, \"iterations:\", iterations)\n",
    "for epoch in range(epochs):\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "    optimizer.zero_grad()\n",
    "    #old code\n",
    "    #loss_train = compute_loss(net, *train_plates_data.values(), rad_x)\n",
    "    #loss_test = compute_loss(net, *test_plates_data.values(), rad_x)\n",
    "    #new code\n",
    "    loss_train = compute_loss(net, *train_plates_data)\n",
    "    loss_test = compute_loss(net, *test_plates_data)\n",
    "    loss_train.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    #print(scheduler.get_lr())\n",
    "    with torch.autograd.no_grad():\n",
    "        train_data.append(float(loss_train.data))\n",
    "        test_data.append(float(loss_test.data)) \n",
    "\n",
    "\n",
    "plt.plot(train_data, c='g', label='train', linewidth=5.0)\n",
    "plt.plot(test_data, c='r', label='test')\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Training\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epsilon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 102\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[39m#plt.suptitle(\"Validation with different radius\")\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     plt\u001b[39m.\u001b[39mshow\n\u001b[1;32m--> 102\u001b[0m create_plot()\n",
      "Cell \u001b[1;32mIn[17], line 79\u001b[0m, in \u001b[0;36mcreate_plot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m new_val_x, new_val_y \u001b[39m=\u001b[39m delete_points_inside_the_hole(val_domain, radii[j][\u001b[39m0\u001b[39m], radii[j][\u001b[39m1\u001b[39m])\n\u001b[0;32m     78\u001b[0m new_val_r \u001b[39m=\u001b[39m  radii[j][\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39mones_like(new_val_x)\n\u001b[1;32m---> 79\u001b[0m new_def_val_x, new_def_val_y, _, _, disp, stress \u001b[39m=\u001b[39m compute_model_prediction(new_val_x, new_val_y, new_val_r)\n\u001b[0;32m     81\u001b[0m tuples \u001b[39m=\u001b[39m [\n\u001b[0;32m     82\u001b[0m     (stress[:, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mStress xx\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mviridis\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m     83\u001b[0m     (stress[:, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mStress xy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mviridis\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m     (disp[:, \u001b[39m1\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mDisplacement in y\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minferno_r\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m ] \n\u001b[0;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n",
      "Cell \u001b[1;32mIn[17], line 28\u001b[0m, in \u001b[0;36mcompute_model_prediction\u001b[1;34m(val_x, val_y, radius)\u001b[0m\n\u001b[0;32m     26\u001b[0m def_val_x \u001b[39m=\u001b[39m val_x\u001b[39m.\u001b[39mdetach() \u001b[39m+\u001b[39m disp[:, \u001b[39m0\u001b[39m]\n\u001b[0;32m     27\u001b[0m def_val_y \u001b[39m=\u001b[39m val_y\u001b[39m.\u001b[39mdetach()\u001b[39m+\u001b[39m disp[:, \u001b[39m1\u001b[39m]\n\u001b[1;32m---> 28\u001b[0m strain \u001b[39m=\u001b[39m epsilon(val_x, val_y, radius, net)\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m     29\u001b[0m stress \u001b[39m=\u001b[39m sigma(strain)\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m     30\u001b[0m residual_x, residual_y \u001b[39m=\u001b[39m pde_residual(val_x, val_y, radius, net)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epsilon' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a validation domain different from the training domain\n",
    "val_x, val_y = np.meshgrid(np.linspace(0, L, 50), np.linspace(0, L, 50))\n",
    "val_r = np.linspace(Min_Ra_x, Max_Ra_x, 2500)\n",
    "val_ry = val_r\n",
    "for i in range(2500):\n",
    "    val_ry[i] = (SuAr/(pi*val_r[i])) \n",
    "val_domain = np.vstack([val_x.ravel(), val_y.ravel(), val_r, val_ry]).T\n",
    "#oldcode\n",
    "#val_domain = val_domain[((val_domain[:,0] ** 2)/(Re_xnew**2)) + ((val_domain[:,1] ** 2)/(Re_ynew**2)) > 1]\n",
    "#newcode\n",
    "val_domain = val_domain[((val_domain[:,0] ** 2)/(0.0001**2)) + ((val_domain[:,1] ** 2)/(0.0001**2)) > 1]\n",
    "val_x = torch.tensor(val_domain[:,0], requires_grad=True).float()\n",
    "val_y = torch.tensor(val_domain[:,1], requires_grad=True).float()\n",
    "val_r = torch.tensor(val_domain[:,1], requires_grad=True).float()\n",
    "\n",
    "\n",
    "def delete_points_inside_the_hole(val_domain, Re_x, Re_y):\n",
    "    val_domain = val_domain[((val_domain[:,0] ** 2)/(Re_x**2)) + ((val_domain[:,1] ** 2)/((Re_y)**2)) > 1]\n",
    "    val_x = torch.tensor(val_domain[:,0], requires_grad=True).float()\n",
    "    val_y = torch.tensor(val_domain[:,1], requires_grad=True).float()\n",
    "    return val_x, val_y\n",
    "\n",
    "def compute_model_prediction(val_x, val_y, radius):\n",
    "    inputs = torch.column_stack([val_x, val_y, radius])\n",
    "    disp = net(inputs).detach()\n",
    "    def_val_x = val_x.detach() + disp[:, 0]\n",
    "    def_val_y = val_y.detach()+ disp[:, 1]\n",
    "    strain = epsilon(val_x, val_y, radius, net).detach()\n",
    "    stress = sigma(strain).detach()\n",
    "    residual_x, residual_y = pde_residual(val_x, val_y, radius, net)\n",
    "    return def_val_x, def_val_y, residual_x, residual_y, disp, stress\n",
    "\n",
    "\n",
    "def create_subplot(def_val_x,def_val_y,variable, title, cmap, boundary_points):\n",
    "    #top \n",
    "    plt.plot(boundary_points[0].detach(), boundary_points[1].detach(), \"--k\")\n",
    "    #right\n",
    "    plt.plot(boundary_points[2], boundary_points[3], \"--k\")\n",
    "    #bottom\n",
    "    plt.plot(boundary_points[6], boundary_points[7], \"--k\")\n",
    "    #left\n",
    "    plt.plot(boundary_points[4], boundary_points[5], \"--k\")\n",
    "    #hole\n",
    "    plt.plot(boundary_points[8].detach(), boundary_points[9].detach(), \"--k\")\n",
    "    plt.scatter(def_val_x, def_val_y, c=variable, cmap=cmap)\n",
    "    plt.axis(\"equal\")\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    \n",
    "    \n",
    "def create_subplot_new(def_val_x,def_val_y,variable, title, cmap, __, top_points, right_points, left_points, bottom_points, hole_points):\n",
    "    #top \n",
    "    plt.plot(top_points[0].detach(), top_points[1].detach(), \"--k\")\n",
    "    #right\n",
    "    plt.plot(right_points[0], right_points[1], \"--k\")\n",
    "    #bottom\n",
    "    plt.plot(bottom_points[0], bottom_points[1], \"--k\")\n",
    "    #left\n",
    "    plt.plot(left_points[0], left_points[1], \"--k\")\n",
    "    #hole\n",
    "    plt.plot(hole_points[0].detach(), hole_points[1].detach(), \"--k\")\n",
    "    plt.scatter(def_val_x, def_val_y, c=variable, cmap=cmap)\n",
    "    plt.axis(\"equal\")\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "\n",
    "def create_plot():\n",
    "\n",
    "    radii = [\n",
    "        (0.3, 0.8333333333333334),\n",
    "        (0.5, 0.5),\n",
    "        (0.7, 0.35714285714285715)\n",
    "    ]\n",
    "\n",
    "    for j in range(3):\n",
    "        k = j+1\n",
    "        new_val_x, new_val_y = delete_points_inside_the_hole(val_domain, radii[j][0], radii[j][1])\n",
    "        new_val_r =  radii[j][0]*torch.ones_like(new_val_x)\n",
    "        new_def_val_x, new_def_val_y, _, _, disp, stress = compute_model_prediction(new_val_x, new_val_y, new_val_r)\n",
    "\n",
    "        tuples = [\n",
    "            (stress[:, 0, 0], \"Stress xx\", \"viridis\"),\n",
    "            (stress[:, 0, 1], \"Stress xy\", \"viridis\"),\n",
    "            (stress[:, 1, 1], \"Stress yy\", \"viridis\"), \n",
    "            (disp[:, 0], \"Displacement in x\", \"inferno\"),\n",
    "            (disp[:, 1], \"Displacement in y\", \"inferno_r\")\n",
    "        ] \n",
    "        for i in range(5):\n",
    "            plt.subplot(5,3,k)\n",
    "            k += 3 \n",
    "            p1 = Plate(*radii[j], L, P)\n",
    "            data_points = p1.generate_dataset_new(*radii[j], L, N)\n",
    "            create_subplot_new(new_def_val_x,new_def_val_y,*tuples[i],*data_points)\n",
    "            #old code\n",
    "            #data_points = p1.generate_dataset_test(*radii[j], L, N)\n",
    "            #create_subplot(new_def_val_x,new_def_val_y,*tuples[i],data_points[1])\n",
    "    plt.subplots_adjust(top = 3.99, right = 2.49, hspace=0.8, wspace=0.4)\n",
    "    #plt.suptitle(\"Validation with different radius\")\n",
    "    plt.show\n",
    "\n",
    "\n",
    "create_plot()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of maximum stress at hole to high resolution FEM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEM solution with 74745 elements\n",
    "r_data = torch.tensor([0.300, 0.350, 0.400, 0.450, 0.500, 0.550, 0.600, 0.650, 0.700, 0.750, 0.800], requires_grad=True)\n",
    "s_data = torch.tensor([1.615, 1.259, 1.047, 0.896, 0.776, 0.743, 0.845, 0.950, 1.062, 1.182, 1.315])\n",
    "plt.plot(r_data.detach(), s_data, \"ok\")\n",
    "\n",
    "# Evaluate stress with PINN at upper point in hole P1\n",
    "r_opti = torch.linspace(0.3, 0.8, 100, requires_grad=True)\n",
    "x_opti = torch.zeros_like(r_opti, requires_grad=True)\n",
    "y_opti = 0.25 / r_opti\n",
    "s_opti = sigma(epsilon(x_opti, y_opti, r_opti, net))\n",
    "plt.plot(r_opti.detach(), s_opti[:,0,0].detach(), \"k\")\n",
    "\n",
    "# Evaluate stress with PINN at upper point in hole P2\n",
    "r_opti = torch.linspace(0.3, 0.8, 100, requires_grad=True)\n",
    "x_opti = 0.25 / r_opti\n",
    "y_opti = torch.zeros_like(r_opti, requires_grad=True)\n",
    "s_opti = sigma(epsilon(x_opti, y_opti, r_opti, net))\n",
    "plt.plot(r_opti.detach(), -s_opti[:,1,1].detach(), \"k\")\n",
    "\n",
    "# Plot style\n",
    "plt.legend([\"PINN P1\", \"PINN P2\", \"FEM\"])\n",
    "plt.xlabel(\"Radius r_1\")\n",
    "plt.ylabel(\"Stress Ïƒ_11(x0)\")\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6933803a5eb07aa171dba084d46899879b6a552acafe73210d45516dbe23e991"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
