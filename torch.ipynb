{
   "cells": [
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Simple PINN for an elastic plate with an elliptical hole "
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Geometry\n",
            "\n",
            "We want to model a quarter of a plate with an elliptical hole. The domain itself is represented by collocation points, the boundaries are represented by uniformly sampled points along the perimeter."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import torch\n",
            "from torch.optim.lr_scheduler import StepLR\n",
            "import numpy as np\n",
            "from scipy.stats import qmc\n",
            "from plotly.express.colors import sequential\n",
            "import plotly.graph_objects as go\n",
            "import plotly.figure_factory as ff\n",
            "from tqdm import tqdm\n",
            "import wandb\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "torch.set_default_dtype(torch.float64)\n",
            "from global_constants import L, R, B0, EPS0, MU, LBD, RATIO\n",
            "\n",
            "torch.set_default_dtype(torch.float64)\n",
            "\n",
            "# Elliptical axis in x direction\n",
            "Rx = 0.3\n",
            "# Number of collocation points\n",
            "N = 25\n",
            "\n",
            "# Epochs\n",
            "epochs = 8000\n",
            "# second epochs for second optimizer\n",
            "epochs2 = 4000\n",
            "# Batch size\n",
            "batch_size = 64\n",
            "# Leanring rate\n",
            "lr = 0.001\n",
            "# Scheduler step width\n",
            "scheduler_step = 2000 \n",
            "# Gamma factor of scheduler\n",
            "scheduler_gamma = 0.5\n",
            "\n",
            "# Number of hidden neurons\n",
            "hn = 50\n",
            "\n",
            "# Weight of PDE loss\n",
            "W_PDE = 0.00\n",
            "# Weight of Neumann loss\n",
            "W_NEU = 0.0\n",
            "# Weight of data losses\n",
            "W_STRESS = 0.0\n",
            "W_DISP = 0.0\n",
            "\n",
            "# Weights and Biases\n",
            "#wandb.login( key = \"9351c110385f8824931c4f4479b39f325a89051e\" )\n",
            "\n",
            "\n",
            "wandb.init(\n",
            "    project=\"pinn_shape_optimization\",\n",
            "    entity=\"ddped\",\n",
            "    config={\n",
            "        \"Rx\": Rx,\n",
            "        \"N_collo\": N,\n",
            "        \"epochs\": epochs,\n",
            "        \"batch_size\": batch_size,\n",
            "        \"learning_rate\": lr,\n",
            "        \"scheduler_step\": scheduler_step,\n",
            "        \"scheduler_gamma\": scheduler_gamma,\n",
            "        \"hidden_neurons\": hn,\n",
            "        \"n_layers\": 5,\n",
            "        \"data_type\": \"Stress\",\n",
            "        \"W_DATA_STRESS\": W_STRESS,\n",
            "        \"W_DATA_DISP\": W_DISP,\n",
            "        \"W_NEUMANN\": W_NEU,\n",
            "        \"W_PDE\": W_PDE,\n",
            "    },\n",
            ")\n",
            "\n",
            "# Load reference data\n",
            "data_input = torch.as_tensor(\n",
            "    np.loadtxt(f\"data/inputs_Rx={Rx}.csv\", delimiter=\",\")\n",
            ")\n",
            "data_output = torch.as_tensor(\n",
            "    np.loadtxt(f\"data/outputs_Rx={Rx}.csv\", delimiter=\",\"))\n",
            "\n",
            "# Create collocation points\n",
            "points = L * qmc.LatinHypercube(d=2).random(N**2)\n",
            "Ry = R**2 / Rx\n",
            "mask = (((points[:, 0] ** 2) / (Rx**2)) + ((points[:, 1] ** 2) / (Ry**2))) > 1\n",
            "collocation = torch.tensor(points[mask], requires_grad=True)\n",
            "\n",
            "#additional collocation points\n",
            "border = L * qmc.LatinHypercube(d=2).random(8*N**2)\n",
            "upperRy = Ry + 0.3 \n",
            "upperRx = Rx + 0.3\n",
            "bordermask = (((border[:, 0] ** 2) / (upperRx**2)) + ((border[:, 1] ** 2) / (upperRy**2))) < 1\n",
            "bordermask2 = ((((border[bordermask][:, 0] ** 2) / (Rx**2)) + ((border[bordermask][:, 1] ** 2) / (Ry**2))) > 1)\n",
            "bordermask3 = (border[bordermask][bordermask2][:, 0] <  0.20)\n",
            "#bordermask4 = (border[bordermask][bordermask2][bordermask3][:, 1] <  0.95)\n",
            "addi_collo = torch.tensor(border[bordermask][bordermask2][bordermask3], requires_grad=True).double()\n",
            "complete_collo = torch.cat((collocation, addi_collo), 0)\n",
            "\n",
            "# Boundary points\n",
            "x_top = torch.linspace(0, L, N, requires_grad=True).double()\n",
            "y_top = L * torch.ones((N, 1), requires_grad=True).double()\n",
            "top = torch.column_stack([x_top, y_top]).double()\n",
            "\n",
            "NN = int(N * (L - Rx) / L)\n",
            "x_bottom = torch.linspace(Rx, L, NN).double()\n",
            "y_bottom = torch.zeros((NN, 1)).double()\n",
            "bottom = torch.column_stack([x_bottom, y_bottom]).double()\n",
            "\n",
            "NN = int(N * (L - Ry) / L)\n",
            "x_left = torch.zeros((NN, 1)).double()\n",
            "y_left = torch.linspace(Ry, L, NN).double()\n",
            "left = torch.column_stack([x_left, y_left]).double()\n",
            "\n",
            "x_right = L * torch.ones((N, 1)).double()\n",
            "y_right = torch.linspace(0, L, N).double()\n",
            "right = torch.column_stack([x_right, y_right]).double()\n",
            "\n",
            "phi = np.linspace(0, 0.5 * np.pi, int(N * np.pi * Rx / L))\n",
            "x_hole = torch.tensor(Rx * np.cos(phi), requires_grad=True)\n",
            "y_hole = torch.tensor(Ry * np.sin(phi), requires_grad=True)\n",
            "n_hole = torch.tensor(np.stack([-Ry * np.cos(phi), -Rx * np.sin(phi)]).T)\n",
            "n_hole = n_hole / torch.linalg.norm(n_hole, axis=1)[:, None]\n",
            "hole = torch.column_stack([x_hole, y_hole]).double()\n",
            "\n",
            "# Visualize geometry\n",
            "with torch.no_grad():\n",
            "    mode = \"markers\"\n",
            "    gray = dict(color=\"#C9C5BC\")\n",
            "    green = dict(color=\"#006561\")\n",
            "    black = dict(color=\"black\")\n",
            "    fig = ff.create_quiver(\n",
            "        hole[:, 0], hole[:, 1], n_hole[:, 0], n_hole[:, 1], marker=black\n",
            "    )\n",
            "    fig.add_trace(\n",
            "        go.Scatter(x=collocation[:, 0], y=collocation[:, 1], mode=mode, marker=gray)\n",
            "    )\n",
            "    fig.add_trace(go.Scatter(x=top[:, 0], y=top[:, 1], mode=mode, marker=green))\n",
            "    fig.add_trace(go.Scatter(x=bottom[:, 0], y=bottom[:, 1], mode=mode, marker=green))\n",
            "    fig.add_trace(go.Scatter(x=left[:, 0], y=left[:, 1], mode=mode, marker=green))\n",
            "    fig.add_trace(go.Scatter(x=right[:, 0], y=right[:, 1], mode=mode, marker=green))\n",
            "    fig.add_trace(go.Scatter(x=hole[:, 0], y=hole[:, 1], mode=mode, marker=black))\n",
            "    fig.layout.yaxis.scaleanchor = \"x\"\n",
            "    fig.update_layout(\n",
            "        template=\"none\",\n",
            "        width=400,\n",
            "        height=400,\n",
            "        margin=dict(l=0, r=0, b=0, t=0),\n",
            "        showlegend=False,\n",
            "    )\n",
            "    fig.update_xaxes(visible=False)\n",
            "    fig.update_yaxes(visible=False)\n",
            "    wandb.log({\"problem_visualization\": fig})\n",
            "    fig.show()"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## The ANN model that approximates the displacement field\n",
            "\n",
            "An ANN might be considered as a generic function approximator. In this case, it should approximated the function $u: \\mathcal{R}^2 \\rightarrow \\mathcal{R}^2$ with five hidden layers having 20 neurons each."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "class Net(torch.nn.Module):\n",
            "    def __init__(self):\n",
            "        super(Net, self).__init__()\n",
            "        self.hidden_layer1 = torch.nn.Linear(2, hn)\n",
            "        self.hidden_layer2 = torch.nn.Linear(hn, hn)\n",
            "        self.hidden_layer3 = torch.nn.Linear(hn, hn)\n",
            "        self.hidden_layer4 = torch.nn.Linear(hn, hn)\n",
            "        self.hidden_layer5 = torch.nn.Linear(hn, hn)\n",
            "        # self.hidden_layer6 = torch.nn.Linear(hn, hn)\n",
            "        # self.hidden_layer7 = torch.nn.Linear(hn, hn)\n",
            "        # self.hidden_layer8 = torch.nn.Linear(hn, hn)\n",
            "        self.output_layer = torch.nn.Linear(hn, 2)\n",
            "\n",
            "    def forward(self, inputs):\n",
            "        layer1_out = torch.tanh(self.hidden_layer1(inputs))\n",
            "        layer2_out = torch.tanh(self.hidden_layer2(layer1_out))\n",
            "        layer3_out = torch.tanh(self.hidden_layer3(layer2_out))\n",
            "        layer4_out = torch.tanh(self.hidden_layer4(layer3_out))\n",
            "        layer5_out = torch.tanh(self.hidden_layer5(layer4_out))\n",
            "        # layer6_out = torch.tanh(self.hidden_layer5(layer5_out))\n",
            "        # layer7_out = torch.tanh(self.hidden_layer5(layer6_out))\n",
            "        # layer8_out = torch.tanh(self.hidden_layer5(layer7_out))\n",
            "        output = self.output_layer(layer5_out)\n",
            "        return output\n",
            "\n",
            "\n",
            "net = Net()"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## The physics\n",
            "\n",
            "We want to solve linear elasticity on the domain, which means ultimately that we want to minimize the residual of the following PDE \n",
            "$$\\frac{\\partial \\sigma_{11}}{\\partial x_1} + \\frac{\\partial \\sigma_{12}}{\\partial x_2} - b_1 = 0$$\n",
            "$$\\frac{\\partial \\sigma_{21}}{\\partial x_1} + \\frac{\\partial \\sigma_{22}}{\\partial x_2} - b_2 = 0$$\n",
            "with stress \n",
            "$$ \\sigma_{ij} = 2\\mu \\varepsilon_{ij} + \\lambda \\varepsilon_{kk} \\delta_{ij} $$\n",
            "and strain \n",
            "$$ \\varepsilon_{ij} = \\frac{1}{2} \\left( \\frac{\\partial u_i}{\\partial x_j} +  \\frac{\\partial u_j}{\\partial x_i}\\right).$$"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def epsilon(x):\n",
            "    # Compute deformation gradient\n",
            "    dudx = torch.func.jacrev(net)(x)\n",
            "    return 0.5 * (dudx + dudx.T)\n",
            "\n",
            "\n",
            "def sigma(x):\n",
            "    # Compute (small deformation) strain\n",
            "    eps = epsilon(x)\n",
            "    # Compute linear elastic strain (assuming plane strain)\n",
            "    return 2.0 * MU * eps + LBD * torch.trace(eps) * torch.eye(2)\n",
            "\n",
            "\n",
            "def pde_residual(x):\n",
            "    # Compute stress gradient\n",
            "    dsdx = torch.func.jacrev(sigma)(x)\n",
            "    # Momentum balance in x direction\n",
            "    residual_x = dsdx[0, 0, 0] + dsdx[0, 1, 1] - B0\n",
            "    # Momentum balance in y direction\n",
            "    residual_y = dsdx[1, 0, 0] + dsdx[1, 1, 1]\n",
            "    return residual_x, residual_y"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "mse = torch.nn.MSELoss()\n",
            "\n",
            "\n",
            "def compute_physics_losses(complete_collo):\n",
            "    # pde\n",
            "    res_x, res_y = torch.vmap(pde_residual)(complete_collo)\n",
            "    zeros = torch.zeros_like(res_x)\n",
            "    pde_error = mse((res_x), zeros) + mse((res_y), zeros)\n",
            "\n",
            "    # left boundary\n",
            "    pred_left = net(left)\n",
            "    bc_left = torch.zeros_like(pred_left[:, 0])\n",
            "    left_error = mse(pred_left[:, 0], bc_left)\n",
            "\n",
            "    # right boundary\n",
            "    pred_right = net(right)\n",
            "    bc_right = EPS0 * L * torch.ones_like(pred_right[:, 0])\n",
            "    right_error = mse(pred_right[:, 0], bc_right)\n",
            "\n",
            "    # bottom boundary\n",
            "    pred_bottom = net(bottom)\n",
            "    bc_bottom = torch.zeros_like(pred_bottom[:, 1])\n",
            "    bottom_error = mse(pred_bottom[:, 1], bc_bottom)\n",
            "\n",
            "    # top boundary\n",
            "    pred_top = net(top)\n",
            "    bc_top = RATIO * EPS0 * L * torch.ones_like(pred_top[:, 1])\n",
            "    top_error = mse(pred_top[:, 1], bc_top)\n",
            "\n",
            "    # hole boundary\n",
            "    stress_hole = torch.vmap(sigma)(hole)\n",
            "    traction = torch.einsum(\"...ij,...j->...i\", stress_hole, n_hole)\n",
            "    zeros = torch.zeros_like(traction[:, 0])\n",
            "    hole_error = mse(traction[:, 0], zeros) + mse(traction[:, 1], zeros)\n",
            "\n",
            "    return (left_error, right_error, bottom_error, top_error, hole_error, pde_error)"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Training "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
            "scheduler = StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
            "history = []\n",
            "\n",
            "print(\"Starting with Adam optimizer...\")\n",
            "for epoch in tqdm(range(epochs)):\n",
            "    # Permutation to shuffle collocation points randomly in each epoch\n",
            "    permutation = torch.randperm(complete_collo.size()[0])\n",
            "\n",
            "    for i in range(0, complete_collo.size()[0], batch_size):\n",
            "        indices = permutation[i : i + batch_size]\n",
            "        collo = complete_collo[indices]\n",
            "        optimizer.zero_grad()\n",
            "\n",
            "        # Compute physics losses\n",
            "        left_l, right_l, bottom_l, top_l, hole_l, pde_l = compute_physics_losses(collo)\n",
            "\n",
            "        # Get samples from reference solution\n",
            "        samples = torch.randperm(data_output.size()[0])[::100]\n",
            "        # Reference solutions\n",
            "        s_data = data_output[samples, 0:3]\n",
            "        e_data = data_output[samples, 4:7]\n",
            "        u_data = data_output[samples, 7:10]\n",
            "        # Predictions\n",
            "        s_pred = torch.vmap(sigma)(data_input[samples, 0:2])\n",
            "        e_pred = torch.vmap(epsilon)(data_input[samples, 0:2])\n",
            "        u_pred = net(data_input[samples, 0:2])\n",
            "        # Compute data losses\n",
            "        ds_xx = mse(s_data[:, 0], s_pred[:, 0, 0])\n",
            "        ds_yy = mse(s_data[:, 1], s_pred[:, 1, 1])\n",
            "        ds_xy = mse(s_data[:, 2], s_pred[:, 0, 1])\n",
            "        stress_l = ds_xx + ds_yy + ds_xy\n",
            "        de_xx = mse(e_data[:, 0], e_pred[:, 0, 0])\n",
            "        de_yy = mse(e_data[:, 1], e_pred[:, 1, 1])\n",
            "        de_xy = mse(e_data[:, 2], e_pred[:, 0, 1])\n",
            "        strain_l = de_xx + de_yy + de_xy\n",
            "        du_x = mse(u_data[:, 0], u_pred[:, 0])\n",
            "        du_y = mse(u_data[:, 1], u_pred[:, 1])\n",
            "        disp_l = du_x + du_y\n",
            "\n",
            "        # Aggregate losses\n",
            "        dirichlet_losses = left_l + right_l + bottom_l + top_l\n",
            "        loss = (\n",
            "            dirichlet_losses\n",
            "            + W_NEU * hole_l\n",
            "            + W_PDE * pde_l\n",
            "            + W_STRESS * stress_l\n",
            "            + W_DISP * disp_l\n",
            "        )\n",
            "\n",
            "        # Make optimization step after batch\n",
            "        loss.backward(retain_graph=True)\n",
            "        optimizer.step()\n",
            "\n",
            "    # Make scheduler step after full epoch\n",
            "    scheduler.step()\n",
            "    \n",
            "    # append loss to history (=for plotting)\n",
            "    with torch.autograd.no_grad():\n",
            "        history.append(float(loss.data))\n",
            "\n",
            "\n",
            "print(\"Switching to LBFGS optimizer for fine tuning...\")\n",
            "optimizer = torch.optim.LBFGS(net.parameters())\n",
            "\n",
            "for epoch in tqdm(range(epochs2)):\n",
            "    def closure():\n",
            "        optimizer.zero_grad()\n",
            "\n",
            "        # Compute physics losses\n",
            "        left_l, right_l, bottom_l, top_l, hole_l, pde_l = compute_physics_losses(collo)\n",
            "\n",
            "        # Get samples from reference solution\n",
            "        samples = torch.randperm(data_output.size()[0])[::100]\n",
            "        # Reference solutions\n",
            "        s_data = data_output[samples, 0:3]\n",
            "        e_data = data_output[samples, 4:7]\n",
            "        u_data = data_output[samples, 7:10]\n",
            "        # Predictions\n",
            "        s_pred = torch.vmap(sigma)(data_input[samples, 0:2])\n",
            "        e_pred = torch.vmap(epsilon)(data_input[samples, 0:2])\n",
            "        u_pred = net(data_input[samples, 0:2])\n",
            "        # Compute data losses\n",
            "        ds_xx = mse(s_data[:, 0], s_pred[:, 0, 0])\n",
            "        ds_yy = mse(s_data[:, 1], s_pred[:, 1, 1])\n",
            "        ds_xy = mse(s_data[:, 2], s_pred[:, 0, 1])\n",
            "        stress_l = ds_xx + ds_yy + ds_xy\n",
            "        de_xx = mse(e_data[:, 0], e_pred[:, 0, 0])\n",
            "        de_yy = mse(e_data[:, 1], e_pred[:, 1, 1])\n",
            "        de_xy = mse(e_data[:, 2], e_pred[:, 0, 1])\n",
            "        strain_l = de_xx + de_yy + de_xy\n",
            "        du_x = mse(u_data[:, 0], u_pred[:, 0])\n",
            "        du_y = mse(u_data[:, 1], u_pred[:, 1])\n",
            "        disp_l = du_x + du_y\n",
            "\n",
            "        # Aggregate losses\n",
            "        dirichlet_losses = left_l + right_l + bottom_l + top_l\n",
            "        loss = (\n",
            "            dirichlet_losses\n",
            "            + W_NEU * hole_l\n",
            "            + W_PDE * pde_l\n",
            "            + W_STRESS * stress_l\n",
            "            + W_DISP * disp_l\n",
            "        )\n",
            "\n",
            "        # Make optimization step after batch\n",
            "        loss.backward(retain_graph=True)\n",
            "        # append loss to history (=for plotting)\n",
            "        with torch.autograd.no_grad():\n",
            "            history.append(float(loss.data))\n",
            "        return loss\n",
            "    optimizer.step(closure)\n",
            "\n",
            "\n",
            "plt.plot(history, c='g', label='train', linewidth=2.0)\n",
            "plt.yscale(\"log\")\n",
            "plt.title(\"Training\")\n",
            "plt.ylabel(\"Loss\")\n",
            "plt.xlabel(\"Epoch\")\n",
            "plt.legend()\n",
            "plt.show()\n",
            "\n",
            "    # with torch.autograd.no_grad():\n",
            "    #     wandb.log(\n",
            "    #         {\n",
            "    #             \"loss\": loss,\n",
            "    #             \"left_loss\": left_l,\n",
            "    #             \"right_loss\": right_l,\n",
            "    #             \"bottom_loss\": bottom_l,\n",
            "    #             \"top_loss\": top_l,\n",
            "    #             \"hole_loss\": hole_l,\n",
            "    #             \"pde_loss\": pde_l,\n",
            "    #             \"du_x\": du_x,\n",
            "    #             \"du_y\": du_y,\n",
            "    #             \"ds_xx\": ds_xx,\n",
            "    #             \"ds_xy\": ds_xy,\n",
            "    #             \"ds_yy\": ds_yy,\n",
            "    #             \"de_xx\": de_xx,\n",
            "    #             \"de_xy\": de_xy,\n",
            "    #             \"de_yy\": de_yy,\n",
            "    #         }\n",
            "    #     )"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Visualization of results"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Create a validation domain different from the training domain\n",
            "val_x, val_y = np.meshgrid(np.linspace(0, L, 50), np.linspace(0, L, 50))\n",
            "val_domain = np.vstack([val_x.ravel(), val_y.ravel()]).T\n",
            "mask = (\n",
            "    ((val_domain[:, 0] ** 2) / (Rx**2)) + ((val_domain[:, 1] ** 2) / (Ry**2))\n",
            ") > 1\n",
            "val = torch.tensor(val_domain[mask], requires_grad=True)\n",
            "\n",
            "# Compute model predictions on the validation domain\n",
            "disp = net(val)\n",
            "def_val = val + disp\n",
            "stress = torch.vmap(sigma)(val)\n",
            "mises = torch.sqrt(\n",
            "    stress[:, 0, 0] ** 2\n",
            "    + stress[:, 1, 1] ** 2\n",
            "    - stress[:, 0, 0] * stress[:, 1, 1]\n",
            "    + 3 * stress[:, 0, 1] ** 2\n",
            ")\n",
            "# print([loss.item() for loss in compute_les(val)])\n",
            "\n",
            "\n",
            "@torch.no_grad()\n",
            "def make_plot(x, y, variable, title, cmap=sequential.Viridis, size=8.0):\n",
            "    fig = go.Figure()\n",
            "\n",
            "    # Plot boundaries\n",
            "    m = dict(color=\"black\")\n",
            "    fig.add_trace(go.Scatter(x=top[:, 0], y=top[:, 1], mode=\"lines\", marker=m))\n",
            "    fig.add_trace(go.Scatter(x=bottom[:, 0], y=bottom[:, 1], mode=\"lines\", marker=m))\n",
            "    fig.add_trace(go.Scatter(x=left[:, 0], y=left[:, 1], mode=\"lines\", marker=m))\n",
            "    fig.add_trace(go.Scatter(x=right[:, 0], y=right[:, 1], mode=\"lines\", marker=m))\n",
            "    fig.add_trace(go.Scatter(x=hole[:, 0], y=hole[:, 1], mode=\"lines\", marker=m))\n",
            "\n",
            "    # Plot variable values\n",
            "    m = dict(color=variable, colorscale=cmap, size=size, colorbar=dict(thickness=10))\n",
            "    fig.add_trace(go.Scatter(x=x, y=y, marker=m, mode=\"markers\"))\n",
            "\n",
            "    # plot settings\n",
            "    fig.layout.yaxis.scaleanchor = \"x\"\n",
            "    fig.update_layout(\n",
            "        template=\"none\", width=400, height=400, title=title, showlegend=False\n",
            "    )\n",
            "    fig.update_xaxes(visible=False)\n",
            "    fig.update_yaxes(visible=False)\n",
            "    wandb.log({f\"chart_{title}\": fig})\n",
            "    fig.show()\n",
            "\n",
            "\n",
            "# Compute stress data error\n",
            "s_data = data_output[:, 0:3]\n",
            "s_pred = torch.vmap(sigma)(data_input[:, 0:2])\n",
            "ds_xx = s_data[:, 0] - s_pred[:, 0, 0]\n",
            "ds_yy = s_data[:, 1] - s_pred[:, 1, 1]\n",
            "ds_xy = s_data[:, 2] - s_pred[:, 0, 1]\n",
            "\n",
            "# Compute strain data error\n",
            "e_data = data_output[:, 4:7]\n",
            "e_pred = torch.vmap(epsilon)(data_input[:, 0:2])\n",
            "de_xx = e_data[:, 0] - e_pred[:, 0, 0]\n",
            "de_yy = e_data[:, 1] - e_pred[:, 1, 1]\n",
            "de_xy = e_data[:, 2] - e_pred[:, 0, 1]\n",
            "\n",
            "res_x, res_y = torch.vmap(pde_residual)(collocation)\n",
            "\n",
            "# Plot PDE residual\n",
            "make_plot(*collocation.T, res_x, \"Residual x\")\n",
            "make_plot(*collocation.T, res_y, \"Residual y\")\n",
            "\n",
            "# Hole residual\n",
            "resh_x, resh_y = torch.vmap(pde_residual)(hole)\n",
            "make_plot(*hole.T, resh_x, \"Residual x\")\n",
            "make_plot(*hole.T, resh_y, \"Residual y\")\n",
            "\n",
            "# # Hole error \n",
            "# strain_hole = torch.vmap(epsilon)(hole)\n",
            "# stress_hole = torch.vmap(sigma)(hole)\n",
            "# normal_strain = torch.einsum(\"...ij,...j->...i\", strain_hole, n_hole)\n",
            "# normal_stress = torch.einsum(\"...ij,...j->...i\", stress_hole, n_hole)\n",
            "\n",
            "# Plot stress errors\n",
            "cmap = sequential.RdBu_r\n",
            "make_plot(*data_input[:, 0:2].T, ds_xx, \"Stress error xx\", size=2.0, cmap=cmap)\n",
            "make_plot(*data_input[:, 0:2].T, ds_yy, \"Stress error yy\", size=2.0, cmap=cmap)\n",
            "make_plot(*data_input[:, 0:2].T, ds_xy, \"Stress error xy\", size=2.0, cmap=cmap)\n",
            "\n",
            "# Plot strain errors\n",
            "cmap = sequential.RdBu_r\n",
            "make_plot(*data_input[:, 0:2].T, de_xx, \"Strain error xx\", size=2.0, cmap=cmap)\n",
            "make_plot(*data_input[:, 0:2].T, de_yy, \"Strain error yy\", size=2.0, cmap=cmap)\n",
            "make_plot(*data_input[:, 0:2].T, de_xy, \"Strain error xy\", size=2.0, cmap=cmap)\n",
            "\n",
            "# Plot stresses\n",
            "make_plot(*def_val.T, stress[:, 0, 0], \"Stress xx\")\n",
            "make_plot(*def_val.T, stress[:, 0, 1], \"Stress xy\")\n",
            "make_plot(*def_val.T, stress[:, 1, 1], \"Stress yy\")\n",
            "make_plot(*def_val.T, mises, \"Mises stress\")\n",
            "\n",
            "# Plot displacements\n",
            "make_plot(*def_val.T, disp[:, 0], \"Displacement in x\", cmap=sequential.Inferno)\n",
            "make_plot(*def_val.T, disp[:, 1], \"Displacement in y\", cmap=sequential.Inferno)\n",
            "\n",
            "# Finish tracking\n",
            "wandb.finish()"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "pytorch",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.9.13"
      },
      "vscode": {
         "interpreter": {
            "hash": "578dd1749cd7a4cd4ca9aa2aa31ddd8a39c768a81580b28f257ef59bc72538ca"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}